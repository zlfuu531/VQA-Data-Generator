"""
è¯„åˆ¤æ¨¡å— (Refactored)
ä½¿ç”¨è¯„åˆ¤æ¨¡å‹æ¥åˆ¤æ–­æ¨¡å‹ç­”æ¡ˆä¸GTæ˜¯å¦ä¸€è‡´ï¼Œé‡‡ç”¨ JSON ç»“æ„åŒ–è¾“å‡ºä»¥ç¡®ä¿è§£æå‡†ç¡®æ€§ã€‚
"""
import os
import sys
import base64
import time
import json
import re
from typing import Optional, Tuple

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from openai import OpenAI
from module2.config import API_CONFIG, MODEL_CONFIG
from utils import compare_answers  # å‡è®¾è¿™æ˜¯ä½ çš„å…œåº•å­—ç¬¦ä¸²æ¯”è¾ƒå‡½æ•°

def clean_json_text(text: str) -> str:
    """
    ä»æ¨¡å‹è¾“å‡ºä¸­æå– JSON å­—ç¬¦ä¸²ã€‚
    å…¼å®¹æ¨¡å‹è¾“å‡º ```json ... ``` åŒ…è£¹çš„æƒ…å†µã€‚
    """
    text = text.strip()
    # å°è¯•åŒ¹é… ```json {...} ``` æˆ– {...}
    pattern = r"```json\s*(\{.*?\})\s*```|(\{.*\})"
    match = re.search(pattern, text, re.DOTALL)
    if match:
        # è·å–åŒ¹é…åˆ°çš„ç¬¬ä¸€ä¸ªéç©ºç»„
        return match.group(1) or match.group(2)
    
    # å¦‚æœæ²¡æ‰¾åˆ°ä»£ç å—ï¼Œå°è¯•ç›´æ¥å¯»æ‰¾å·¦å³å¤§æ‹¬å·åŒ…è£¹çš„å†…å®¹
    start = text.find('{')
    end = text.rfind('}')
    if start != -1 and end != -1:
        return text[start:end+1]
    
    return text

def judge_answer_with_model(model_answer: str, gt_answer: str, question: str, 
                            image_path: Optional[str] = None, options: Optional[dict] = None) -> Tuple[bool, str, float, Optional[dict], str]:
    """
    ä½¿ç”¨è¯„åˆ¤æ¨¡å‹åˆ¤æ–­æ¨¡å‹ç­”æ¡ˆä¸GTæ˜¯å¦ä¸€è‡´
    
    Returns:
        (is_match, reasoning, response_time, raw_response_json, final_prompt)
        - is_match: æ˜¯å¦åŒ¹é…
        - reasoning: è¯„åˆ¤ç†ç”±
        - response_time: å“åº”æ—¶é—´ï¼ˆç§’ï¼‰
        - raw_response_json: åŸå§‹APIå“åº”ï¼ˆå­—å…¸æ ¼å¼ï¼‰
        - final_prompt: æœ€ç»ˆæäº¤ç»™æ¨¡å‹çš„å®Œæ•´æç¤ºè¯ï¼ˆç”¨äºæ—¥å¿—è®°å½•ï¼‰
    """
    start_time = time.time()
    
    try:
        # --- 1. é…ç½®åŠ è½½ ---
        judge_model_name = MODEL_CONFIG.get("judge_model")
        if not judge_model_name:
            raise ValueError("MODEL_CONFIG ä¸­æœªé…ç½® 'judge_model' å­—æ®µ")
        
        if judge_model_name not in API_CONFIG:
            raise ValueError(
                f"judge_model é…ç½® '{judge_model_name}' åœ¨ API_CONFIG ä¸­ä¸å­˜åœ¨ã€‚"
                f"å¯ç”¨çš„é…ç½®: {list(API_CONFIG.keys())}"
            )
        
        api_config = API_CONFIG[judge_model_name]
        
        # éªŒè¯å¿…è¦çš„é…ç½®å­—æ®µ
        required_fields = ["base_url", "api_key", "model"]
        missing_fields = [f for f in required_fields if not api_config.get(f)]
        if missing_fields:
            raise ValueError(
                f"judge_model é…ç½® '{judge_model_name}' ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}"
            )
        
        client = OpenAI(
            base_url=api_config["base_url"],
            api_key=api_config["api_key"]
        )
        model_name = api_config["model"]
        
        # --- 2. æ„å»ºç»“æ„åŒ–æç¤ºè¯ (System Prompt + User Prompt) ---
        # æ ¸å¿ƒæŒ‡ä»¤ï¼šå®šä¹‰è¯„åˆ¤æ ‡å‡†å’Œè¾“å‡ºæ ¼å¼
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼ä¸”æ™ºèƒ½çš„ç­”æ¡ˆè¯„åˆ¤ç³»ç»Ÿã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ¤æ–­[æ¨¡å‹è¾“å‡º]ä¸[æ ‡å‡†ç­”æ¡ˆ]åœ¨è¯­ä¹‰ä¸Šæ˜¯å¦ä¸€è‡´ã€‚

è¯·éµå¾ªä»¥ä¸‹è¯„åˆ¤æ ‡å‡†ï¼š
1. **è¯­ä¹‰ä¼˜å…ˆ**ï¼šå¦‚æœå«ä¹‰ç›¸åŒä½†è¡¨è¾¾æ–¹å¼ä¸åŒï¼ˆä¾‹å¦‚"10.5"ä¸"10.50"ï¼Œ"åŒ—äº¬"ä¸"ä¸­å›½åŒ—äº¬"ï¼‰ï¼Œåº”åˆ¤å®šä¸º Trueã€‚
2. **å¿½ç•¥æ ¼å¼**ï¼šå¿½ç•¥æ ‡ç‚¹ç¬¦å·ã€Markdownæ ¼å¼ã€å¤§å°å†™çš„å·®å¼‚ã€‚
3. **å…³é”®ä¿¡æ¯**ï¼šå¦‚æœé¢˜ç›®è¦æ±‚è®¡ç®—æ•°å€¼ï¼Œæ•°å€¼å¿…é¡»å‡†ç¡®ï¼›å¦‚æœè¦æ±‚è§£é‡Šï¼Œæ ¸å¿ƒé€»è¾‘å¿…é¡»ä¸€è‡´ã€‚
4. **å¤šé€‰ç­”æ¡ˆ**ï¼šå¦‚æœæ ‡å‡†ç­”æ¡ˆåŒ…å«å¤šä¸ªç»“æœï¼ˆä¾‹å¦‚å¤šé€‰é¢˜ç›®æˆ–è€…å¤šä¸ªé—®é¢˜ï¼‰ï¼Œæ¨¡å‹ç­”æ¡ˆå¿…é¡»åŒ…å«æ‰€æœ‰æ­£ç¡®ç­”æ¡ˆä¸”ä¸€ä¸€å¯¹åº”æ­£ç¡®æ‰ç®—æ­£ç¡®ã€‚éƒ¨åˆ†æ­£ç¡®åº”åˆ¤å®šä¸º Falseã€‚

âš ï¸ **è¾“å‡ºæ ¼å¼è¦æ±‚**ï¼š
è¯·ä»…è¾“å‡ºä¸€ä¸ªæ ‡å‡†çš„ JSON å¯¹è±¡ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–è§£é‡Šæ€§æ–‡å­—æˆ–Markdownæ ‡è®°ã€‚æ ¼å¼å¦‚ä¸‹ï¼š
{
    "result": true,  // å¦‚æœä¸€è‡´ä¸º trueï¼Œä¸ä¸€è‡´ä¸º false
    "reasoning": "è¿™é‡Œå†™ç®€çŸ­çš„åˆ¤å®šç†ç”±"
}
"""

        user_content_text = f"""
[é—®é¢˜]
{question}
"""
        
        # å¦‚æœå­˜åœ¨é€‰é¡¹ï¼Œæ·»åŠ åˆ°æç¤ºè¯ä¸­
        if options is not None and isinstance(options, dict) and options:
            opt_str = "ï¼›".join([f"{k}: {v}" for k, v in options.items()])
            user_content_text += f"""
[é€‰é¡¹]
{opt_str}
"""
        
        user_content_text += f"""
[æ ‡å‡†ç­”æ¡ˆ (GT)]
{gt_answer}

[æ¨¡å‹ç­”æ¡ˆ]
{model_answer}

æ³¨æ„ï¼šåªéœ€è¦æ¯”è¾ƒç­”æ¡ˆéƒ¨åˆ†ï¼Œä¸éœ€è¦è€ƒè™‘æ€è€ƒè¿‡ç¨‹ï¼ˆprocessï¼‰ã€‚

è¯·æ ¹æ®ä¸Šè¿°å†…å®¹ç”Ÿæˆ JSON è¯„åˆ¤ç»“æœã€‚
"""

        # --- 3. æ„å»ºæ¶ˆæ¯ä½“ ---
        messages = [{"role": "system", "content": system_prompt}]
        
        user_message_content = []
        user_message_content.append({"type": "text", "text": user_content_text})

        # å¤„ç†å›¾ç‰‡
        #æ˜¯å¦è¾“å…¥å›¾ç‰‡ï¼ï¼ï¼ï¼ï¼ï¼ï¼
        
        # ================== ä¿®æ”¹å¼€å§‹ï¼šæ³¨é‡Šæ‰å›¾ç‰‡å¤„ç† ==================
        # å¤„ç†å›¾ç‰‡
        # if image_path and os.path.exists(image_path):
        #     with open(image_path, "rb") as image_file:
        #         base64_image = base64.b64encode(image_file.read()).decode('utf-8')
        #     user_message_content.append({
        #         "type": "image_url",
        #         "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}
        #     })
        # ================== ä¿®æ”¹ç»“æŸ ==================
        
        messages.append({"role": "user", "content": user_message_content})




        

        # --- 4. è°ƒç”¨ API ---
        print(f"      [è¯„åˆ¤æ¨¡å‹] ({model_name}) å¼€å§‹åˆ¤æ–­...")
        
        # æ„å»ºAPIè°ƒç”¨å‚æ•°
        api_params = {
            "model": model_name,
            "messages": messages,
            "max_tokens": api_config.get("max_tokens", 512),
            "timeout": api_config.get("timeout", 120)
        }
        # ä»…å½“æ˜¾å¼é…ç½®äº†æ¸©åº¦æ—¶æ‰ä¼ é€’ï¼Œé¿å…è¦†ç›–æ¨¡å‹é»˜è®¤å€¼
        if api_config.get("temperature") is not None:
            api_params["temperature"] = api_config["temperature"]
        
        # å¦‚æœæ¨¡å‹æ”¯æŒJSONæ¨¡å¼ï¼Œæ·»åŠ è¯¥å‚æ•°ï¼ˆæŸäº›æ¨¡å‹å¯èƒ½ä¸æ”¯æŒï¼‰
        try:
            response = client.chat.completions.create(
                **api_params,
                response_format={"type": "json_object"}
            )
        except Exception as json_format_error:
            # å¦‚æœJSONæ¨¡å¼ä¸æ”¯æŒï¼Œå›é€€åˆ°æ™®é€šæ¨¡å¼
            print(f"      [è¯„åˆ¤æ¨¡å‹] âš ï¸ JSONæ¨¡å¼ä¸æ”¯æŒï¼Œä½¿ç”¨æ™®é€šæ¨¡å¼: {json_format_error}")
            response = client.chat.completions.create(**api_params)

        # --- 5. ä¿å­˜åŸå§‹å“åº”JSON ---
        raw_response_json = None
        try:
            # å°†å“åº”å¯¹è±¡è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            if hasattr(response, 'model_dump'):
                raw_response_json = response.model_dump()
            elif hasattr(response, 'dict'):
                raw_response_json = response.dict()
            else:
                # æ‰‹åŠ¨æ„å»ºå“åº”å­—å…¸
                raw_response_json = {
                    "id": getattr(response, 'id', None),
                    "object": getattr(response, 'object', None),
                    "created": getattr(response, 'created', None),
                    "model": getattr(response, 'model', None),
                    "choices": []
                }
                if hasattr(response, 'choices') and response.choices:
                    for choice in response.choices:
                        choice_dict = {
                            "index": getattr(choice, 'index', None),
                            "finish_reason": getattr(choice, 'finish_reason', None),
                            "message": {}
                        }
                        if hasattr(choice, 'message'):
                            msg = choice.message
                            choice_dict["message"] = {
                                "role": getattr(msg, 'role', None),
                                "content": getattr(msg, 'content', None),
                            }
                        raw_response_json["choices"].append(choice_dict)
        except Exception as e:
            print(f"      [è¯„åˆ¤æ¨¡å‹] âš ï¸ è­¦å‘Šï¼šæ— æ³•åºåˆ—åŒ–åŸå§‹å“åº”: {e}")
            raw_response_json = None
        
        # --- 6. æ„å»ºæœ€ç»ˆæç¤ºè¯ï¼ˆç”¨äºæ—¥å¿—è®°å½•ï¼‰ ---
        final_prompt = f"{system_prompt}\n\n{user_content_text}"
        
        # --- 7. è§£æç»“æœ ---
        if not response.choices or len(response.choices) == 0:
            raise ValueError("APIå“åº”ä¸­æ²¡æœ‰choiceså­—æ®µ")
        
        raw_content = response.choices[0].message.content
        if not raw_content:
            raise ValueError("APIå“åº”å†…å®¹ä¸ºç©º")
        
        cleaned_content = clean_json_text(raw_content)
        
        try:
            result_json = json.loads(cleaned_content)
            is_match = bool(result_json.get("result", False)) # é»˜è®¤ä¸º False ä»¥é˜²ä¸‡ä¸€
            reasoning = result_json.get("reasoning", "æœªæä¾›ç†ç”±") or "æœªæä¾›ç†ç”±"
        except json.JSONDecodeError as e:
            # å¦‚æœJSONè§£æå¤±è´¥ï¼Œè®°å½•æ—¥å¿—å¹¶å›é€€åˆ°è§„åˆ™åŒ¹é…ï¼ˆé˜²æ­¢ç¨‹åºå´©æºƒï¼‰
            print(f"      [è¯„åˆ¤æ¨¡å‹] âš ï¸ JSONè§£æå¤±è´¥: {e}")
            print(f"      [è¯„åˆ¤æ¨¡å‹] åŸå§‹å†…å®¹ï¼ˆå‰200å­—ç¬¦ï¼‰: {raw_content[:200]}...")
            reasoning = f"JSONè§£æé”™è¯¯: {str(e)}"
            # é™çº§ç­–ç•¥ï¼šç®€å•çš„å…³é”®è¯åŒ¹é…
            content_lower = raw_content.lower()
            # æŸ¥æ‰¾æ˜ç¡®çš„true/falseæ ‡è®°
            if '"result": true' in content_lower or '"result":true' in content_lower:
                is_match = True
            elif '"result": false' in content_lower or '"result":false' in content_lower:
                is_match = False
            else:
                # æœ€åçš„å€”å¼ºï¼šæŸ¥æ‰¾true/falseå…³é”®è¯
                is_match = "true" in content_lower and "false" not in content_lower

        response_time = time.time() - start_time
        
        status_icon = "âœ…" if is_match else "âŒ"
        print(f"      [è¯„åˆ¤æ¨¡å‹] {status_icon} ç»“æœ: {'ä¸€è‡´' if is_match else 'ä¸ä¸€è‡´'} | è€—æ—¶: {response_time:.2f}s | ç†ç”±: {reasoning[:50]}...")
        
        return is_match, reasoning, response_time, raw_response_json, final_prompt

    except Exception as e:
        error_msg = f"è¯„åˆ¤è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {str(e)}"
        response_time = time.time() - start_time
        print(f"      [è¯„åˆ¤æ¨¡å‹] ğŸš¨ å¼‚å¸¸: {error_msg}")
        
        # é™çº§ç­–ç•¥ï¼šä½¿ç”¨åŸºäºè§„åˆ™çš„å­—ç¬¦ä¸²æ¯”è¾ƒ
        print("      [è¯„åˆ¤æ¨¡å‹] ğŸ”„ é™çº§ä¸ºå­—ç¬¦ä¸²ç²¾ç¡®åŒ¹é…...")
        is_match = compare_answers(model_answer, gt_answer)
        # æ„å»ºæœ€ç»ˆæç¤ºè¯ï¼ˆå³ä½¿å¤±è´¥ä¹Ÿè®°å½•ï¼‰
        final_prompt = f"{system_prompt}\n\n{user_content_text}" if 'system_prompt' in locals() and 'user_content_text' in locals() else ""
        return is_match, f"æ¨¡å‹è¯„åˆ¤å¤±è´¥({str(e)})ï¼Œå·²è½¬ä¸ºè§„åˆ™åŒ¹é…", response_time, None, final_prompt