"""
æ¨¡å—2ï¼šæ¨¡å‹è¯„ä¼°æ¨¡å— (Refactored for Config Integration)
åŠŸèƒ½ï¼šè°ƒç”¨ä¸‰æ–¹æ¨¡å‹ -> ç­”æ¡ˆæ¯”å¯¹ (Judge) -> éš¾åº¦åˆ†çº§ (Classifier)
ç‰¹ç‚¹ï¼šå®Œå…¨åŸºäº config.py é©±åŠ¨ï¼Œæ”¯æŒå¤šçº¿ç¨‹ã€æ–­ç‚¹ç»­ä¼ ã€JSONLæ”¯æŒ
"""
import os
import sys
import argparse
import time
import json
import re
import threading
import signal
import atexit
from datetime import datetime
from typing import List, Dict, Optional, Set
from concurrent.futures import ThreadPoolExecutor, as_completed

# å°è¯•å¯¼å…¥ tqdm ç”¨äºæ˜¾ç¤ºè¿›åº¦æ¡
try:
    from tqdm import tqdm
except ImportError:
    tqdm = None

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥é…ç½®ï¼ˆä»…æ¨¡å‹ä¸è£åˆ¤æ¨¡å‹ç›¸å…³é…ç½®ï¼‰
from module2.config import MODEL_CONFIG
from utils import ensure_dir, load_json, save_json
from module2.answer_comparison import AnswerComparison
from module2.classifier import QAClassifier
from module2.judge import judge_answer_with_model
from module2.logger import init_log_file, log_model_response, close_log_file

DEFAULT_PROCESSING_CONFIG = {
    "max_workers": 4,   # å¹¶å‘çº¿ç¨‹æ•°
    "batch_size": 4,    # æ‰¹é‡ä¿å­˜å¤§å°
    "debug_mode": False # æ˜¯å¦æ‰“å°æ›´å¤šè°ƒè¯•ä¿¡æ¯
}

# æ¨¡å‹é”®åˆ—è¡¨ï¼ˆé¿å…åœ¨å¤šå¤„é‡å¤ï¼‰
MODEL_KEYS = ["model1", "model2", "model3"]

# éš¾åº¦çº§åˆ«åˆ—è¡¨
DIFFICULTY_LEVELS = ["L1", "L2", "L3", "L4"]

# çº¿ç¨‹é”
file_lock = threading.Lock()

class Module2ModelEvaluation:
    """æ¨¡å—2ï¼šæ¨¡å‹è¯„ä¼°å™¨"""
    
    def __init__(
        self,
        output_dir: Optional[str] = None,
        max_workers: Optional[int] = None,
        batch_size: Optional[int] = None,
        debug_mode: Optional[bool] = None,
    ):
        """
        åˆå§‹åŒ–æ¨¡å‹è¯„ä¼°å™¨
        """
        # 1. ç¡®å®šè¾“å‡ºç›®å½•ï¼šä¼˜å…ˆä½¿ç”¨å‚æ•°ï¼Œå¦åˆ™é»˜è®¤ <project_root>/output/module2
        project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        default_output_dir = os.path.join(project_root, "output", "module2")
        self.output_dir = output_dir if output_dir else default_output_dir
        ensure_dir(self.output_dir)
        
        # è¿è¡Œå‚æ•°ï¼ˆå¯ç”±å‘½ä»¤è¡Œè¦†ç›–ï¼‰
        self.max_workers = max_workers if max_workers is not None else DEFAULT_PROCESSING_CONFIG["max_workers"]
        self.batch_size = batch_size if batch_size is not None else DEFAULT_PROCESSING_CONFIG["batch_size"]
        self.debug_mode = debug_mode if debug_mode is not None else DEFAULT_PROCESSING_CONFIG["debug_mode"]

        # åˆå§‹åŒ–å­æ¨¡å—
        self.answer_comparison = AnswerComparison(debug_mode=self.debug_mode)  # è´Ÿè´£æ¨¡å‹è°ƒç”¨
        self.classifier = QAClassifier()  # è´Ÿè´£åˆ†çº§
        
        # æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆå°†åœ¨ batch_evaluate ä¸­åˆå§‹åŒ–ï¼‰
        self.log_file_path = None
        
        # ä¸­æ–­ä¿å­˜ç›¸å…³å˜é‡
        self._final_results_for_save = []  # å­˜å‚¨å¾…ä¿å­˜çš„ç»“æœ
        self._retry_results_for_save = []  # å­˜å‚¨å¾…ä¿å­˜çš„é‡è¯•ç»“æœ
        self._output_file_for_save = None  # è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºä¿å­˜ï¼‰
        self._out_dir_for_save = None  # è¾“å‡ºç›®å½•ï¼ˆç”¨äºä¿å­˜ï¼‰
        self._saved_result_ids_for_save = set()  # å·²ä¿å­˜çš„ç»“æœID
        self._shutdown_requested = False  # æ˜¯å¦è¯·æ±‚å…³é—­
        
        # è¾“å‡ºæ ¼å¼ç›¸å…³å˜é‡
        self._output_format = "jsonl"  # è¾“å‡ºæ ¼å¼ï¼šjson æˆ– jsonlï¼ˆæ ¹æ®æ–‡ä»¶æ‰©å±•åè‡ªåŠ¨åˆ¤æ–­ï¼‰
        self._result_buffer = []  # JSON æ ¼å¼çš„æ‰¹é‡å†™å…¥ç¼“å†²åŒº
        self._buffer_lock = threading.Lock()  # ç¼“å†²åŒºé”
    
    @staticmethod
    def _get_model_config(model_key: str) -> Dict:
        """
        å®‰å…¨è·å–æ¨¡å‹é…ç½®
        
        Args:
            model_key: æ¨¡å‹é”®ï¼ˆ"model1", "model2", "model3"ï¼‰
        
        Returns:
            æ¨¡å‹é…ç½®å­—å…¸ï¼ˆå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›ç©ºå­—å…¸ï¼‰
        """
        return MODEL_CONFIG.get(model_key, {})
    
    @staticmethod
    def _get_model_name(model_key: str) -> str:
        """
        è·å–æ¨¡å‹åç§°
        
        Args:
            model_key: æ¨¡å‹é”®
        
        Returns:
            æ¨¡å‹åç§°ï¼ˆå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²ï¼‰
        """
        return Module2ModelEvaluation._get_model_config(model_key).get("name", "")
    
    @staticmethod
    def _derive_output_dir(base_output_file: str) -> str:
        """
        ä»è¾“å‡ºæ–‡ä»¶è·¯å¾„æ¨å¯¼è¾“å‡ºç›®å½•ï¼ˆä¸ _save_by_level_and_summary é€»è¾‘ä¸€è‡´ï¼‰
        
        Args:
            base_output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¦‚ "xxx.json"ï¼‰
        
        Returns:
            è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆå¦‚ "xxx/"ï¼‰
        """
        parent_dir = os.path.dirname(base_output_file)
        base_name = os.path.basename(base_output_file)
        if "." in base_name:
            name_part, _ = os.path.splitext(base_name)
        else:
            name_part = base_name
        return os.path.join(parent_dir, name_part)
    
    @staticmethod
    def _round_sort_key(k: str) -> tuple:
        """
        å¤šè½®é—®é¢˜æ’åºé”®ï¼šä¼˜å…ˆæŒ‰æ•°å­—å¤§å°æ’åº
        
        Args:
            k: è½®æ¬¡é”®ï¼ˆå¦‚ "round1", "round10"ï¼‰
        
        Returns:
            æ’åºé”®å…ƒç»„ (æ•°å­—, åŸå­—ç¬¦ä¸²)
        """
        m = re.search(r"(\d+)", str(k))
        if m:
            return int(m.group(1)), str(k)
        return 0, str(k)

    def _normalize_items(self, items: List[Dict]) -> List[Dict]:
        """
        å°†è¾“å…¥ç»Ÿä¸€è§„èŒƒä¸ºåŸºäº module1 è¾“å‡ºå­—æ®µçš„ç»“æ„ã€‚
        çº¦å®šï¼šä¸Šæ¸¸å°±æ˜¯ module1 çš„è¾“å‡ºï¼š
        - image_id / image_path / image_type
        - question_id / question_type / question / options / answer / qa_make_process
        åœ¨æ­¤åŸºç¡€ä¸Šï¼Œä»…è¡¥å……å†…éƒ¨ä½¿ç”¨çš„ id å­—æ®µï¼ˆç­‰äº question_idï¼‰ã€‚
        
        æ³¨æ„ï¼šå¦‚æœè¾“å…¥ä¸­æ²¡æœ‰ qa_make_process å­—æ®µï¼Œåˆ™ä¿æŒä¸ºç©ºï¼ˆä¸æ·»åŠ æˆ–è®¾ä¸ºç©ºå­—ç¬¦ä¸²/ç©ºå­—å…¸ï¼‰ã€‚
        """
        normalized: List[Dict] = []
        for idx, item in enumerate(items):
            if not isinstance(item, dict):
                print(f"âš ï¸ è­¦å‘Šï¼šç¬¬ {idx} æ¡æ•°æ®ä¸æ˜¯å­—å…¸ï¼Œå·²è·³è¿‡")
                continue

            # ä¸¥æ ¼æŒ‰ç…§ module1 è¾“å‡ºç»“æ„è¦æ±‚ï¼šå¿…é¡»åŒ…å« question_id / question / answer
            if "question_id" in item and "question" in item and "answer" in item:
                new_item = dict(item)  # æµ…æ‹·è´ï¼Œä¿ç•™åŸå§‹å­—æ®µ

                # ä½¿ç”¨ question_id ä½œä¸ºå”¯ä¸€ id
                qid = item.get("question_id")
                if not qid:
                    print(f"âš ï¸ è­¦å‘Šï¼šç¬¬ {idx} æ¡æ•°æ®ç¼ºå°‘ question_idï¼Œå·²è·³è¿‡")
                    continue
                new_item["id"] = qid

                # å…¼å®¹å­—æ®µåï¼šå¦‚æœä¸Šæ¸¸åªæä¾› GTï¼Œå¯ä»¥åŒæ­¥åˆ° answer
                if (not new_item.get("answer")) and "GT" in item:
                    new_item["answer"] = item.get("GT", "")

                # ç¡®ä¿ image_path å­—æ®µå­˜åœ¨ï¼ˆå¦‚æœæ²¡æœ‰å°±ç½®ç©ºå­—ç¬¦ä¸²ï¼Œåç»­é€»è¾‘ä¼šåšå®¹é”™ï¼‰
                if "image_path" not in new_item:
                    new_item["image_path"] = ""

                # qa_make_process å­—æ®µï¼šå¦‚æœè¾“å…¥ä¸­æ²¡æœ‰ï¼Œå°±ä¿æŒä¸ºç©ºï¼ˆä¸æ·»åŠ ï¼‰
                # å¦‚æœè¾“å…¥ä¸­æœ‰ä½†ä¸ºç©ºï¼Œä¹Ÿä¿æŒåŸæ ·
                # è¿™æ ·è¾“å‡ºæ—¶å¦‚æœæ²¡æœ‰è¿™ä¸ªå­—æ®µï¼Œå°±è¡¨ç¤ºè¾“å…¥æ—¶å°±æ²¡æœ‰

                normalized.append(new_item)
                continue

            # æ— æ³•è¯†åˆ«çš„ç»“æ„ï¼šç»™å‡ºæç¤ºå¹¶è·³è¿‡
            print(f"âš ï¸ è­¦å‘Šï¼šç¬¬ {idx} æ¡æ•°æ®ç¼ºå°‘ module1 è§„èŒƒå­—æ®µï¼ˆquestion_id/question/answerï¼‰ï¼Œå·²è·³è¿‡")
        return normalized

    def _load_data(self, file_path: str) -> List[Dict]:
        """
        æ™ºèƒ½åŠ è½½æ•°æ®ï¼Œæ”¯æŒ json å’Œ jsonl
        """
        if not file_path:
            raise ValueError("è¾“å…¥æ–‡ä»¶è·¯å¾„ä¸èƒ½ä¸ºç©º")
        
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            
        if file_path.endswith('.jsonl'):
            data = []
            with open(file_path, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        item = json.loads(line)
                        # éªŒè¯å¿…è¦å­—æ®µ
                        if not isinstance(item, dict):
                            print(f"è­¦å‘Šï¼šç¬¬ {line_num} è¡Œä¸æ˜¯æœ‰æ•ˆçš„JSONå¯¹è±¡ï¼Œè·³è¿‡")
                            continue
                        data.append(item)
                    except json.JSONDecodeError as e:
                        print(f"è­¦å‘Šï¼šç¬¬ {line_num} è¡ŒJSONè§£æå¤±è´¥: {e}ï¼Œè·³è¿‡")
                        continue
            if not data:
                raise ValueError(f"JSONLæ–‡ä»¶ {file_path} ä¸­æ²¡æœ‰æœ‰æ•ˆæ•°æ®")
            return self._normalize_items(data)
        else:
            # å‡è®¾æ˜¯æ ‡å‡† JSON
            try:
                content = load_json(file_path)
            except Exception as e:
                raise ValueError(f"æ— æ³•åŠ è½½JSONæ–‡ä»¶ {file_path}: {e}")
            
            if isinstance(content, list):
                if not content:
                    raise ValueError(f"JSONæ–‡ä»¶ {file_path} ä¸ºç©ºåˆ—è¡¨")
                return self._normalize_items(content)
            elif isinstance(content, dict) and "items" in content:
                items = content["items"]
                if not isinstance(items, list):
                    raise ValueError(f"JSONæ–‡ä»¶ {file_path} ä¸­çš„ 'items' å­—æ®µä¸æ˜¯åˆ—è¡¨")
                if not items:
                    raise ValueError(f"JSONæ–‡ä»¶ {file_path} ä¸­çš„ 'items' åˆ—è¡¨ä¸ºç©º")
                return self._normalize_items(items)
            else:
                raise ValueError(f"æ— æ³•è§£æ JSON æ–‡ä»¶ç»“æ„: {file_path}ã€‚æœŸæœ›æ ¼å¼ï¼šåŒ…å« 'items' å­—æ®µçš„å¯¹è±¡æˆ–JSONæ•°ç»„")

    def _build_model_question(self, item: Dict) -> str:
        """
        å°† module1 çš„å­—æ®µç»„è£…æˆé€‚åˆä¸‹æ¸¸æ¨¡å‹å›ç­”çš„ç»Ÿä¸€æ–‡æœ¬é—®é¢˜ï¼š
        - æ”¯æŒå•è½® & å¤šè½®
        - æ”¯æŒå¸¦ options çš„é€‰æ‹©é¢˜
        
        âš ï¸ æç¤ºè¯æ‹¼æ¥æµç¨‹è¯´æ˜ï¼š
        1. å•è½®é¢˜ï¼š
           - æœ¬æ–¹æ³•æ„å»ºå®Œæ•´é—®é¢˜æ–‡æœ¬ï¼ˆåŒ…å«é¢˜å‹ã€å›¾ç‰‡ç±»å‹ã€é—®é¢˜ã€é€‰é¡¹ã€æ ¼å¼è¦æ±‚ï¼‰
           - è¿”å›çš„æ–‡æœ¬ä½œä¸º question å‚æ•°ä¼ ç»™ call_model*_api
           - call_model*_api ä½¿ç”¨ PROMPT_TEMPLATE.format(question=question) æ‹¼æ¥
           - æœ€ç»ˆæç¤ºè¯ = PROMPT_TEMPLATE + æœ¬æ–¹æ³•æ„å»ºçš„é—®é¢˜æ–‡æœ¬
        
        2. å¤šè½®é¢˜ï¼š
           - æœ¬æ–¹æ³•æ„å»ºå®Œæ•´çš„å¤šè½®é—®é¢˜æ–‡æœ¬ï¼ˆåŒ…å«æ‰€æœ‰ round çš„é—®é¢˜å’Œæ ¼å¼è¦æ±‚ï¼‰
           - ä½†å®é™…è°ƒç”¨æ—¶ï¼Œqa_item ä¸­çš„ Q_rounds æ˜¯å­—å…¸æ ¼å¼
           - åœ¨ answer_comparison.py çš„ get_model_answer_multi_round ä¸­ï¼Œæ¯ä¸€è½®å•ç‹¬æ„é€  round_question
           - ç¬¬ä¸€è½®ï¼šround_question = "round1ï¼š{é—®é¢˜æ–‡æœ¬}"ï¼ˆç¼ºå°‘æ ¼å¼è¦æ±‚ï¼ï¼‰
           - åç»­è½®ï¼šround_question = "å†å²å¯¹è¯\n\nç°åœ¨æ˜¯æ–°çš„è½®æ¬¡ round2ï¼Œè¯·åªå›ç­”æœ¬è½®é—®é¢˜ï¼š{é—®é¢˜æ–‡æœ¬}"ï¼ˆç¼ºå°‘æ ¼å¼è¦æ±‚ï¼ï¼‰
           - éœ€è¦ä¿®å¤ï¼šåœ¨æ„é€  round_question æ—¶æ·»åŠ æ ¼å¼è¦æ±‚
        """
        image_type = item.get("image_type", "")
        qtype = item.get("question_type", "")
        question = item.get("question", "")
        options = item.get("options", None)

        parts = []
        if qtype:
            parts.append(f"ã€é¢˜å‹ã€‘{qtype}")
        if image_type:
            parts.append(f"ã€å›¾ç‰‡ç±»å‹ã€‘{image_type}")

        # å¤šè½®é¢˜ï¼šquestion ä¸º dictï¼Œå½¢å¦‚ {"round1": "...", "round2": "..."}
        if isinstance(question, dict):
            parts.append("ã€å¤šè½®é—®é¢˜ã€‘")
            for rk in sorted(question.keys(), key=self._round_sort_key):
                q_text = question.get(rk, "")
                parts.append(f"{rk}ï¼š{q_text}")

            # å¤šè½®é€‰é¡¹ï¼ˆå¦‚å¤šè½®å•é€‰é¢˜ï¼‰
            if isinstance(options, dict):
                parts.append("ã€å¤šè½®é€‰é¡¹ã€‘")
                for rk in sorted(options.keys(), key=self._round_sort_key):
                    opt_dict = options.get(rk, {})
                    if isinstance(opt_dict, dict):
                        opt_str = "ï¼›".join([f"{k}: {v}" for k, v in opt_dict.items()])
                        parts.append(f"{rk} é€‰é¡¹ï¼š{opt_str}")
        else:
            # å•è½®é—®é¢˜
            parts.append(f"ã€é—®é¢˜ã€‘{question}")

            # å•è½®é€‰é¡¹ï¼šå•é€‰ / å¤šé€‰ / åˆ¤æ–­
            if isinstance(options, dict):
                opt_str = "ï¼›".join([f"{k}: {v}" for k, v in options.items()])
                parts.append(f"ã€é€‰é¡¹ã€‘{opt_str}")

        return "\n".join(parts)

    def step1_call_models(self, item: Dict, skip_existing: bool = False) -> Dict:
        """
        æ­¥éª¤1ï¼šè°ƒç”¨ä¸‰ä¸ªæ¨¡å‹è·å–ç­”æ¡ˆ
        
        Args:
            item: æ•°æ®é¡¹
            skip_existing: æ˜¯å¦è·³è¿‡å·²æœ‰ç»“æœçš„æ¨¡å‹ï¼ˆç”¨äºé”™è¯¯é‡è¯•ï¼‰
        """
        question = item.get("question", "")

        # å•è½®é¢˜ï¼šç›´æ¥æ„é€ ç»Ÿä¸€æ–‡æœ¬é—®é¢˜
        if not isinstance(question, dict):
            qa_item = {
                "Q": self._build_model_question(item),
                "Answer": item.get("answer", ""),  # GTç­”æ¡ˆï¼ˆå­—ç¬¦ä¸²ï¼‰
                "image_path": item.get("image_path", ""),
                "id": item.get("id", item.get("question_id", "unknown"))  # ä¼ å…¥é—®é¢˜IDç”¨äºæ—¥å¿—
            }
        else:
            # å¤šè½®é¢˜ï¼šæŒ‰è½®æé—®ï¼Œä¸ä¸€æ¬¡é—®å®Œ
            # æ„å»ºå®Œæ•´çš„é—®é¢˜æ–‡æœ¬ï¼ˆåŒ…å«æ ¼å¼è¦æ±‚ï¼‰ï¼Œç”¨äºæå–æ ¼å¼è¦æ±‚éƒ¨åˆ†
            full_question_text = self._build_model_question(item)
            qa_item = {
                "Q": full_question_text,            # å®Œæ•´é—®é¢˜æ–‡æœ¬ï¼ˆåŒ…å«æ ¼å¼è¦æ±‚ï¼‰ï¼Œç”¨äºæå–æ ¼å¼è¦æ±‚
                "Q_rounds": question,              # {"round1": "...", "round2": "..."}ï¼Œå®é™…çš„é—®é¢˜å†…å®¹
                "Answer": item.get("answer", ""),  # GTç­”æ¡ˆï¼ˆå¤šè½® dictï¼‰
                "image_path": item.get("image_path", ""),
                "id": item.get("id", item.get("question_id", "unknown"))  # ä¼ å…¥é—®é¢˜IDç”¨äºæ—¥å¿—
            }
        
        # å¦‚æœå¼€å¯äº†è·³è¿‡å·²æœ‰ç»“æœçš„æ¨¡å¼ï¼Œä¼ é€’å·²æœ‰çš„æ¨¡å‹ç»“æœ
        if skip_existing:
            for key in MODEL_KEYS:
                if key in item and isinstance(item[key], dict):
                    # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„ç­”æ¡ˆ
                    existing_answer = item[key].get("answer", "")
                    if existing_answer and (isinstance(existing_answer, str) or isinstance(existing_answer, dict)):
                        # ä¼ é€’å·²æœ‰ç»“æœåˆ° qa_itemï¼ŒAnswerComparison ä¼šè·³è¿‡å·²æœ‰ç»“æœçš„æ¨¡å‹
                        qa_item[key] = item[key]
        
        # è°ƒç”¨ AnswerComparison æ¨¡å—
        # æ³¨æ„ï¼šAnswerComparison å†…éƒ¨åº”è¯¥ä¹Ÿè¯»å–äº† config æ¥å†³å®šè°ƒç”¨å“ªäº›æ¨¡å‹
        # è¿™é‡Œæˆ‘ä»¬åšäºŒæ¬¡æ ¡éªŒå’Œæ ¼å¼åŒ–
        compared_item = self.answer_comparison.compare_three_models(qa_item)
        
        result = item.copy()
        
        # åˆ¤æ–­æ˜¯å¦æ˜¯å¤šè½®é¢˜
        is_multi_round = isinstance(question, dict)
        
        # ç»Ÿä¸€å¤„ç† model1, model2, model3
        for key in MODEL_KEYS:
            # è·å– config ä¸­çš„å¼€å…³çŠ¶æ€
            config_enabled = self._get_model_config(key).get("enabled", False)
            
            # è·å–æ¨¡å‹è¿”å›çš„æ•°æ®
            m_data = compared_item.get(key, {})
            
            # åªæœ‰å½“ config å¯ç”¨ä¸”æ¨¡å‹ç¡®å®è¿”å›äº†æ•°æ®æ—¶ï¼Œæ‰æ ‡è®°ä¸º enabled
            is_actually_enabled = config_enabled and m_data.get("enabled", True)

            # ç»Ÿä¸€ä½¿ç”¨ process å­—æ®µï¼ˆä¼˜å…ˆä½¿ç”¨ processï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ cot ä½œä¸ºå…¼å®¹ï¼‰
            # å¤šè½®é¢˜ï¼šprocess ä¸ºå­—å…¸æ ¼å¼ï¼›å•è½®é¢˜ï¼šä¸ºå­—ç¬¦ä¸²æ ¼å¼
            default_process = {} if is_multi_round else ""
            process_value = m_data.get("process", default_process)
            if not process_value and not is_multi_round:
                # å•è½®é¢˜çš„å…¼å®¹å¤„ç†ï¼šå°è¯•ä½¿ç”¨ cot å­—æ®µ
                process_value = m_data.get("cot", "")
            
            # å¤šè½®é¢˜ï¼šanswer ä¸ºå­—å…¸æ ¼å¼ï¼›å•è½®é¢˜ï¼šä¸ºå­—ç¬¦ä¸²æ ¼å¼
            default_answer = {} if is_multi_round else ""
            answer_value = m_data.get("answer", default_answer)
            
            result[key] = {
                "enabled": is_actually_enabled,
                "process": process_value,
                "answer": answer_value,
                "model_name": m_data.get("model_name", self._get_model_name(key)),
                "response_time": m_data.get("response_time", 0.0),
                "match_gt": False  # å ä½ï¼Œæ­¥éª¤2è®¡ç®—
            }

        result["comparison"] = compared_item.get("comparison", {})
        return result
    
    def step2_compare_with_gt(self, item: Dict) -> Dict:
        """
        æ­¥éª¤2ï¼šä½¿ç”¨è¯„åˆ¤æ¨¡å‹ (Judge)
        """
        gt_answer = item.get("answer", "")
        question = item.get("question", "")
        image_path = item.get("image_path", "")
        options = item.get("options", None)
        is_multi_round = isinstance(question, dict) and isinstance(gt_answer, dict)
        
        # éªŒè¯å¿…è¦å­—æ®µ
        if not question:
            print(f"âš ï¸ è­¦å‘Šï¼šitem {item.get('id', 'unknown')} ç¼ºå°‘ question å­—æ®µ")
        if not gt_answer:
            print(f"âš ï¸ è­¦å‘Šï¼šitem {item.get('id', 'unknown')} ç¼ºå°‘ answer (GT) å­—æ®µ")
        
        for model_key in MODEL_KEYS:
            model_data = item.get(model_key, {})
            
            # ç¡®ä¿ model_data æ˜¯å­—å…¸
            if not isinstance(model_data, dict):
                print(f"âš ï¸ è­¦å‘Šï¼šitem {item.get('id', 'unknown')} çš„ {model_key} ä¸æ˜¯å­—å…¸ï¼Œåˆå§‹åŒ–ä¸ºç©ºå­—å…¸")
                model_data = {}
                item[model_key] = model_data
            
            # ä»…è¯„æµ‹å·²å¯ç”¨çš„æ¨¡å‹
            if model_data.get("enabled", False):
                model_answer = model_data.get("answer", "")
                
                if not model_answer:
                    # å¦‚æœå¯ç”¨äº†ä½†æ²¡ç­”æ¡ˆï¼ˆå¯èƒ½APIé”™è¯¯ï¼‰ï¼Œè§†ä¸ºä¸åŒ¹é…
                    model_data["match_gt"] = False
                    continue

                # å¤šè½®é¢˜ï¼šæ¯ä¸ª round å•ç‹¬è¯„åˆ¤
                if is_multi_round:
                    # æ¨¡å‹ç­”æ¡ˆåº”è¯¥æ˜¯å­—å…¸æ ¼å¼ {"round1": "ç­”æ¡ˆ1", "round2": "ç­”æ¡ˆ2"}
                    # å…¼å®¹å¤„ç†ï¼šå¦‚æœæ˜¯å­—ç¬¦ä¸²æ ¼å¼ï¼ˆæ—§æ•°æ®ï¼‰ï¼Œå°è¯•è§£æ
                    model_answers_dict = {}
                    if isinstance(model_answer, dict):
                        # ç›´æ¥ä½¿ç”¨å­—å…¸æ ¼å¼
                        model_answers_dict = model_answer
                    elif isinstance(model_answer, str):
                        # å…¼å®¹æ—§æ ¼å¼ï¼šè§£æå­—ç¬¦ä¸²æ ¼å¼ "round1: ç­”æ¡ˆ1; round2: ç­”æ¡ˆ2"
                        print(f"      âš ï¸ è­¦å‘Šï¼š{model_key} çš„ç­”æ¡ˆæ ¼å¼ä¸ºå­—ç¬¦ä¸²ï¼Œæ­£åœ¨è§£æï¼ˆåº”ä½¿ç”¨å­—å…¸æ ¼å¼ï¼‰")
                        for part in model_answer.split(";"):
                            part = part.strip()
                            if ":" in part:
                                round_key, answer = part.split(":", 1)
                                round_key = round_key.strip()
                                answer = answer.strip()
                                model_answers_dict[round_key] = answer
                    
                    # å¯¹æ¯ä¸ª round è¿›è¡Œè¯„åˆ¤
                    all_rounds_match = True
                    round_results = {}
                    for round_key in sorted(gt_answer.keys(), key=self._round_sort_key):
                        gt_round_answer = gt_answer.get(round_key, "")
                        model_round_answer = model_answers_dict.get(round_key, "")
                        round_question = question.get(round_key, "")
                        # è·å–å¯¹åº”è½®æ¬¡çš„é€‰é¡¹
                        round_options = None
                        if isinstance(options, dict):
                            round_options = options.get(round_key, None)
                        
                        if not model_round_answer:
                            all_rounds_match = False
                            round_results[round_key] = {
                                "match": False,
                                "reasoning": "æ¨¡å‹ç­”æ¡ˆä¸­ç¼ºå°‘è¯¥è½®æ¬¡çš„ç­”æ¡ˆ"
                            }
                            continue
                        
                        try:
                            is_match, judge_reasoning, judge_time = judge_answer_with_model(
                                model_answer=model_round_answer,
                                gt_answer=gt_round_answer,
                                question=round_question,
                                image_path=image_path,
                                options=round_options
                            )
                            round_results[round_key] = {
                                "match": is_match,
                                "reasoning": judge_reasoning,
                                "time": judge_time
                            }
                            if not is_match:
                                all_rounds_match = False
                        except Exception as e:
                            print(f"âš ï¸ è­¦å‘Šï¼šè¯„åˆ¤æ¨¡å‹è°ƒç”¨å¤±è´¥ ({model_key}, {round_key}): {e}ï¼Œä½¿ç”¨å­—ç¬¦ä¸²åŒ¹é…ä½œä¸ºé™çº§æ–¹æ¡ˆ")
                            from utils import compare_answers
                            is_match = compare_answers(model_round_answer, gt_round_answer)
                            round_results[round_key] = {
                                "match": is_match,
                                "reasoning": f"æ¨¡å‹è¯„åˆ¤å¤±è´¥ï¼Œå·²è½¬ä¸ºè§„åˆ™åŒ¹é…: {str(e)}"
                            }
                            if not is_match:
                                all_rounds_match = False
                    
                    model_data["match_gt"] = all_rounds_match
                    # ä¿å­˜æ¯è½®çš„è¯„åˆ¤ç»“æœï¼ˆç”¨äºè°ƒè¯•ï¼‰
                    if self.debug_mode:
                        model_data["judge_reasoning"] = f"å¤šè½®è¯„åˆ¤ç»“æœ: {round_results}"
                        # è®¡ç®—æ€»è¯„åˆ¤æ—¶é—´
                        total_judge_time = sum(r.get("time", 0) for r in round_results.values())
                        model_data["judge_time"] = total_judge_time
                else:
                    # å•è½®é¢˜ï¼šç›´æ¥è¯„åˆ¤
                    try:
                        is_match, judge_reasoning, judge_time = judge_answer_with_model(
                            model_answer=model_answer,
                            gt_answer=gt_answer,
                            question=question if isinstance(question, str) else str(question),
                            image_path=image_path,
                            options=options
                        )
                        
                        model_data["match_gt"] = is_match
                        # å¯é€‰å­—æ®µï¼šjudge_reasoning å’Œ judge_time ç”¨äºè°ƒè¯•ï¼Œä½†ä¸å½±å“ä¸»æµç¨‹
                        if self.debug_mode:
                            model_data["judge_reasoning"] = judge_reasoning
                            model_data["judge_time"] = judge_time
                    except Exception as e:
                        print(f"âš ï¸ è­¦å‘Šï¼šè¯„åˆ¤æ¨¡å‹è°ƒç”¨å¤±è´¥ ({model_key}): {e}ï¼Œä½¿ç”¨å­—ç¬¦ä¸²åŒ¹é…ä½œä¸ºé™çº§æ–¹æ¡ˆ")
                        # é™çº§åˆ°å­—ç¬¦ä¸²åŒ¹é…
                        from utils import compare_answers
                        model_data["match_gt"] = compare_answers(model_answer, gt_answer)
            else:
                # æœªå¯ç”¨çš„æ¨¡å‹
                model_data["match_gt"] = False
        
        return item
    
    def step3_classify(self, item: Dict) -> Dict:
        """
        æ­¥éª¤3ï¼šåˆ†çº§
        """
        # æ„é€  classifier éœ€è¦çš„è¾“å…¥æ ¼å¼
        qa_item = {
            "Q": item.get("question", ""),
            "Answer": item.get("answer", ""),
            "image_path": item.get("image_path", ""),
            "model1": item.get("model1", {}),
            "model2": item.get("model2", {}),
            "model3": item.get("model3", {}),
            "comparison": item.get("comparison", {})
        }
        
        classified = self.classifier.classify_qa_item(qa_item)
        item["classification"] = classified.get("classification", {})
        return item
    
    def _check_model_errors(self, item: Dict) -> Dict:
        """
        æ£€æŸ¥æ¨¡å‹æ˜¯å¦æœ‰å‡ºé”™çš„æƒ…å†µ
        
        Returns:
            åŒ…å«é”™è¯¯ä¿¡æ¯çš„å­—å…¸ï¼Œæ ¼å¼ï¼š{"has_error": bool, "error_models": [model_key, ...], "error_details": {...}}
        """
        error_info = {
            "has_error": False,
            "error_models": [],
            "error_details": {}
        }
        
        question = item.get("question", "")
        is_multi_round = isinstance(question, dict)
        
        for model_key in MODEL_KEYS:
            model_data = item.get(model_key, {})
            if not isinstance(model_data, dict):
                continue
            
            # åªæ£€æŸ¥å¯ç”¨çš„æ¨¡å‹
            if not model_data.get("enabled", False):
                continue
            
            answer = model_data.get("answer", "")
            
            # åˆ¤æ–­æ˜¯å¦å‡ºé”™ï¼šå¯ç”¨äº†ä½†æ²¡æœ‰ç­”æ¡ˆï¼Œæˆ–è€…ç­”æ¡ˆä¸ºç©º
            has_error = False
            error_detail = ""
            
            if is_multi_round:
                # å¤šè½®é¢˜ï¼šanswer åº”è¯¥æ˜¯å­—å…¸æ ¼å¼
                if not isinstance(answer, dict) or not answer:
                    has_error = True
                    error_detail = "å¤šè½®é¢˜ç­”æ¡ˆä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯"
            else:
                # å•è½®é¢˜ï¼šanswer åº”è¯¥æ˜¯å­—ç¬¦ä¸²æ ¼å¼
                if not isinstance(answer, str) or not answer.strip():
                    has_error = True
                    error_detail = "å•è½®é¢˜ç­”æ¡ˆä¸ºç©º"
            
            if has_error:
                error_info["has_error"] = True
                error_info["error_models"].append(model_key)
                error_info["error_details"][model_key] = error_detail
        
        return error_info
    
    def evaluate_item(self, item: Dict, retry_errors: bool = False) -> Dict:
        """
        å•æ¡æ•°æ®å¤„ç†æµæ°´çº¿
        
        Args:
            item: æ•°æ®é¡¹
            retry_errors: æ˜¯å¦ä¸ºé”™è¯¯é‡è¯•æ¨¡å¼ï¼ˆåªè°ƒç”¨ä¹‹å‰å‡ºé”™çš„æ¨¡å‹ï¼‰
        """
        item_id = item.get("id", "unknown")
        
        # éªŒè¯å¿…è¦å­—æ®µ
        required_fields = ["id", "question", "answer"]
        missing_fields = [f for f in required_fields if not item.get(f)]
        if missing_fields:
            error_msg = f"ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}"
            print(f"âŒ Error processing item {item_id}: {error_msg}")
            item["error"] = error_msg
            return item
        
        try:
            # 1. è°ƒç”¨æ¨¡å‹ï¼ˆå¦‚æœæ˜¯é‡è¯•æ¨¡å¼ï¼Œè·³è¿‡å·²æœ‰ç»“æœçš„æ¨¡å‹ï¼‰
            item = self.step1_call_models(item, skip_existing=retry_errors)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¨¡å‹å‡ºé”™
            error_info = self._check_model_errors(item)
            if error_info["has_error"]:
                item["model_error"] = error_info
                print(f"âš ï¸  æ¨¡å‹ç”Ÿæˆé”™è¯¯ (item {item_id}): {error_info['error_models']}")
                # æœ‰æ¨¡å‹å‡ºé”™ï¼Œä¸è¿›è¡Œåç»­çš„è¯„åˆ¤å’Œåˆ†çº§ï¼Œç›´æ¥è¿”å›
                item = self._ensure_output_format(item, include_error=True)
                return item
            else:
                # å¦‚æœä¹‹å‰æœ‰é”™è¯¯æ ‡è®°ï¼Œç°åœ¨å·²è§£å†³ï¼Œæ¸…é™¤é”™è¯¯æ ‡è®°
                if "model_error" in item:
                    del item["model_error"]
            
            # 2. è¯„åˆ¤
            item = self.step2_compare_with_gt(item)
            # 3. åˆ†çº§
            item = self.step3_classify(item)
            
            # ç¡®ä¿è¾“å‡ºæ ¼å¼ç¬¦åˆè§„èŒƒ
            item = self._ensure_output_format(item)
            
            return item
        except Exception as e:
            print(f"âŒ Error processing item {item_id}: {str(e)}")
            if self.debug_mode:
                import traceback
                traceback.print_exc()
            item["error"] = str(e)
            # å³ä½¿å‡ºé”™ä¹Ÿç¡®ä¿åŸºæœ¬ç»“æ„å­˜åœ¨
            item = self._ensure_output_format(item, include_error=True)
            return item
    
    def _ensure_output_format(self, item: Dict, include_error: bool = False) -> Dict:
        """
        ç¡®ä¿è¾“å‡ºæ ¼å¼ç¬¦åˆ data_schema.py å®šä¹‰çš„è§„èŒƒ
        """
        # ç¡®ä¿æ‰€æœ‰æ¨¡å‹å­—æ®µå­˜åœ¨
        for model_key in MODEL_KEYS:
            if model_key not in item:
                item[model_key] = {
                    "enabled": False,
                    "process": "",
                    "answer": "",
                    "model_name": self._get_model_name(model_key),
                    "response_time": 0.0,
                    "match_gt": False
                }
            else:
                # ç¡®ä¿æ¯ä¸ªæ¨¡å‹å­—æ®µå®Œæ•´
                model_data = item[model_key]
                if not isinstance(model_data, dict):
                    model_data = {}
                    item[model_key] = model_data
                
                # ç¡®ä¿æ‰€æœ‰å¿…éœ€å­—æ®µå­˜åœ¨
                model_data.setdefault("enabled", False)
                model_data.setdefault("process", "")
                model_data.setdefault("answer", "")
                model_data.setdefault("model_name", self._get_model_name(model_key))
                model_data.setdefault("response_time", 0.0)
                model_data.setdefault("match_gt", False)
        
        # ç¡®ä¿ comparison å­—æ®µå­˜åœ¨ä¸”å®Œæ•´
        if "comparison" not in item:
            item["comparison"] = {}
        
        comparison = item["comparison"]
        if not isinstance(comparison, dict):
            comparison = {}
            item["comparison"] = comparison
        
        # ç¡®ä¿æ‰€æœ‰å¿…éœ€å­—æ®µå­˜åœ¨
        comparison.setdefault("agreement_with_gt", 0)
        
        # ç¡®ä¿ classification å­—æ®µå­˜åœ¨ä¸”å®Œæ•´
        if "classification" not in item:
            item["classification"] = {}
        
        classification = item["classification"]
        if not isinstance(classification, dict):
            classification = {}
            item["classification"] = classification
        
        # ç¡®ä¿æ‰€æœ‰å¿…éœ€å­—æ®µå­˜åœ¨ï¼ˆç¬¦åˆ data_schema.py å®šä¹‰ï¼‰
        # æ”¯æŒ L1, L2, L3, L4 çº§åˆ«ï¼ˆä¸å†æœ‰ L0ï¼‰
        classification.setdefault("level", "L4")
        classification.setdefault("category", "å¤„ç†å¤±è´¥" if include_error else "æœªåˆ†ç±»")
        classification.setdefault("agreement_count", comparison.get("agreement_with_gt", 0))
        
        return item

    def _write_jsonl_item(self, item: Dict, level: str = None):
        """
        JSONL æ ¼å¼ï¼šå®æ—¶å†™å…¥å•æ¡æ•°æ®åˆ°å¯¹åº”çº§åˆ«çš„æ–‡ä»¶ï¼ˆé€è¡Œè¿½åŠ ï¼‰
        
        Args:
            item: è¦å†™å…¥çš„æ•°æ®é¡¹
            level: éš¾åº¦çº§åˆ«ï¼ˆL1-L4ï¼‰æˆ– "error"ï¼Œå¦‚æœä¸º None åˆ™æ ¹æ® classification è‡ªåŠ¨åˆ¤æ–­
        """
        if self._output_format != "jsonl":
            return False
        
        if not self._out_dir_for_save:
            return False
        
        # ç¡®å®šçº§åˆ«
        if level is None:
            if "model_error" in item or "error" in item:
                level = "error"
            else:
                level = item.get("classification", {}).get("level", "Unknown")
                if level not in DIFFICULTY_LEVELS:
                    level = "L4"
        
        # ç¡®å®šæ–‡ä»¶è·¯å¾„
        if level == "error":
            file_path = os.path.join(self._out_dir_for_save, "error.jsonl")
        else:
            file_path = os.path.join(self._out_dir_for_save, f"{level}.jsonl")
        
        # å®æ—¶å†™å…¥ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        with file_lock:
            try:
                with open(file_path, "a", encoding="utf-8") as f:
                    f.write(json.dumps(item, ensure_ascii=False) + "\n")
                return True
            except Exception as e:
                print(f"âŒ [JSONLå®æ—¶å†™å…¥å¤±è´¥] {e}")
                return False
    
    def _flush_buffer(self):
        """
        æ‰¹é‡å†™å…¥ç¼“å†²åŒºæ•°æ®åˆ°æ–‡ä»¶ï¼ˆä»…ç”¨äº JSON æ ¼å¼ï¼ŒJSONL æ ¼å¼ä¸ä½¿ç”¨æ­¤å‡½æ•°ï¼‰
        """
        if self._output_format == "jsonl":
            return
        
        if not self._out_dir_for_save:
            return
        
        with self._buffer_lock:
            if not self._result_buffer:
                return
            current_batch = list(self._result_buffer)
            self._result_buffer = []
        
        try:
            # æŒ‰çº§åˆ«åˆ†ç±»
            from collections import defaultdict
            level_buckets: Dict[str, List[Dict]] = defaultdict(list)
            error_items = []
            
            for item in current_batch:
                if "model_error" in item or "error" in item:
                    error_items.append(item)
                else:
                    level = item.get("classification", {}).get("level", "Unknown")
                    if level not in DIFFICULTY_LEVELS:
                        level = "L4"
                    level_buckets[level].append(item)
            
            # ä½¿ç”¨çº¿ç¨‹é”ä¿è¯çº¿ç¨‹å®‰å…¨åœ°è¿½åŠ ä¿å­˜
            with file_lock:
                # è¿½åŠ ä¿å­˜åˆ°å„éš¾åº¦çº§åˆ«æ–‡ä»¶
                for lvl in DIFFICULTY_LEVELS:
                    new_items = level_buckets.get(lvl, [])
                    if not new_items:
                        continue
                    
                    lvl_path = os.path.join(self._out_dir_for_save, f"{lvl}.json")
                    # è¯»å–ç°æœ‰æ•°æ®
                    existing_items = []
                    if os.path.isfile(lvl_path):
                        try:
                            existing_data = load_json(lvl_path)
                            if isinstance(existing_data, list):
                                existing_items = existing_data
                        except Exception:
                            existing_items = []
                    
                    # åˆå¹¶å¹¶å»é‡ï¼ˆåŸºäºidï¼‰
                    existing_ids = {str(item.get("id", "")) for item in existing_items}
                    for item in new_items:
                        item_id = str(item.get("id", ""))
                        if item_id not in existing_ids:
                            existing_items.append(item)
                            existing_ids.add(item_id)
                    
                    # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
                    save_json(existing_items, lvl_path)
                
                # è¿½åŠ ä¿å­˜é”™è¯¯ç»“æœ
                if error_items:
                    error_path = os.path.join(self._out_dir_for_save, "error.json")
                    existing_errors = []
                    if os.path.isfile(error_path):
                        try:
                            existing_data = load_json(error_path)
                            if isinstance(existing_data, list):
                                existing_errors = existing_data
                        except Exception:
                            existing_errors = []
                    
                    # åˆå¹¶å¹¶å»é‡
                    existing_error_ids = {str(item.get("id", "")) for item in existing_errors}
                    for item in error_items:
                        item_id = str(item.get("id", ""))
                        if item_id not in existing_error_ids:
                            existing_errors.append(item)
                            existing_error_ids.add(item_id)
                    
                    save_json(existing_errors, error_path)
            
        except Exception as e:
            print(f"âš ï¸ [JSONæ‰¹é‡ä¿å­˜å¤±è´¥] {e}")

    def _save_unsaved_results(self):
        """
        ä¿å­˜æ‰€æœ‰æœªä¿å­˜çš„ç»“æœï¼ˆç”¨äºä¸­æ–­æ—¶è°ƒç”¨ï¼‰
        è¿™ä¸ªæ–¹æ³•å¯ä»¥åœ¨ä¿¡å·å¤„ç†å™¨ã€atexit æˆ–å¼‚å¸¸å¤„ç†ä¸­è°ƒç”¨
        """
        if not self._out_dir_for_save:
            return
        
        # åˆå¹¶æ‰€æœ‰å¾…ä¿å­˜çš„ç»“æœ
        all_unsaved = self._final_results_for_save.copy()
        all_unsaved.extend(self._retry_results_for_save)
        
        # JSONL æ ¼å¼ï¼šè¿˜éœ€è¦ä¿å­˜ buffer ä¸­çš„ç»“æœ
        if self._output_format == "jsonl":
            # JSONL æ ¼å¼ç†è®ºä¸Šå·²ç»å®æ—¶å†™å…¥ï¼Œä½†ä¸ºäº†å®‰å…¨èµ·è§ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æœªå†™å…¥çš„
            # å®é™…ä¸Šï¼ŒJSONL æ ¼å¼ä¸éœ€è¦è¿™ä¸ªå‡½æ•°ï¼Œå› ä¸ºå·²ç»å®æ—¶å†™å…¥äº†
            # ä½†ä¸ºäº†å…¼å®¹ï¼Œæˆ‘ä»¬è¿˜æ˜¯æ£€æŸ¥ä¸€ä¸‹
            if all_unsaved:
                print("\nğŸ’¾ æ­£åœ¨ä¿å­˜æœªä¿å­˜çš„ç»“æœï¼ˆä¸­æ–­ä¿æŠ¤ - JSONLæ ¼å¼ï¼‰...")
                saved_count = 0
                for res in all_unsaved:
                    res_id = str(res.get("id", ""))
                    if res_id and res_id not in self._saved_result_ids_for_save:
                        if self._write_jsonl_item(res):
                            self._saved_result_ids_for_save.add(res_id)
                            saved_count += 1
                if saved_count > 0:
                    print(f"âœ… å·²ä¿å­˜ {saved_count} æ¡æœªä¿å­˜çš„ç»“æœåˆ° {self._out_dir_for_save}")
                else:
                    print("   æ‰€æœ‰ç»“æœå·²ä¿å­˜ï¼Œæ— éœ€é¢å¤–ä¿å­˜")
            return
        
        # JSON æ ¼å¼ï¼šåˆ·æ–° buffer å¹¶ä¿å­˜
        if self._result_buffer:
            self._flush_buffer()
        
        if not all_unsaved:
            return
        
        try:
            print("\nğŸ’¾ æ­£åœ¨ä¿å­˜æœªä¿å­˜çš„ç»“æœï¼ˆä¸­æ–­ä¿æŠ¤ï¼‰...")
            
            # æ‰¾å‡ºå°šæœªä¿å­˜çš„ç»“æœ
            new_results_to_save = []
            for res in all_unsaved:
                res_id = str(res.get("id", ""))
                if res_id and res_id not in self._saved_result_ids_for_save:
                    new_results_to_save.append(res)
                    self._saved_result_ids_for_save.add(res_id)
            
            if not new_results_to_save:
                print("   æ‰€æœ‰ç»“æœå·²ä¿å­˜ï¼Œæ— éœ€é¢å¤–ä¿å­˜")
                return
            
            # åˆ†ç¦»æ­£å¸¸ç»“æœå’Œé”™è¯¯ç»“æœ
            normal_to_save = []
            error_to_save = []
            for item in new_results_to_save:
                if "model_error" in item or "error" in item:
                    error_to_save.append(item)
                else:
                    normal_to_save.append(item)
            
            # æŒ‰éš¾åº¦çº§åˆ«åˆ†ç±»æ­£å¸¸ç»“æœ
            from collections import defaultdict
            level_buckets: Dict[str, List[Dict]] = defaultdict(list)
            for item in normal_to_save:
                level = item.get("classification", {}).get("level", "Unknown")
                if level not in DIFFICULTY_LEVELS:
                    level = "L4"
                level_buckets[level].append(item)
            
            # ä½¿ç”¨çº¿ç¨‹é”ä¿è¯çº¿ç¨‹å®‰å…¨åœ°è¿½åŠ ä¿å­˜
            with file_lock:
                file_ext = ".jsonl" if self._output_format == "jsonl" else ".json"
                
                # è¿½åŠ ä¿å­˜åˆ°å„éš¾åº¦çº§åˆ«æ–‡ä»¶
                for lvl in DIFFICULTY_LEVELS:
                    new_items = level_buckets.get(lvl, [])
                    if not new_items:
                        continue
                    
                    lvl_path = os.path.join(self._out_dir_for_save, f"{lvl}{file_ext}")
                    
                    if self._output_format == "jsonl":
                        # JSONL æ ¼å¼ï¼šé€è¡Œè¿½åŠ 
                        with open(lvl_path, "a", encoding="utf-8") as f:
                            for item in new_items:
                                item_id = str(item.get("id", ""))
                                if item_id and item_id not in self._saved_result_ids_for_save:
                                    f.write(json.dumps(item, ensure_ascii=False) + "\n")
                                    self._saved_result_ids_for_save.add(item_id)
                    else:
                        # JSON æ ¼å¼ï¼šè¯»å–ç°æœ‰æ•°æ®
                        existing_items = []
                        if os.path.isfile(lvl_path):
                            try:
                                existing_data = load_json(lvl_path)
                                if isinstance(existing_data, list):
                                    existing_items = existing_data
                            except Exception:
                                existing_items = []
                        
                        # åˆå¹¶å¹¶å»é‡ï¼ˆåŸºäºidï¼‰
                        existing_ids = {str(item.get("id", "")) for item in existing_items}
                        for item in new_items:
                            item_id = str(item.get("id", ""))
                            if item_id not in existing_ids:
                                existing_items.append(item)
                                existing_ids.add(item_id)
                        
                        # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
                        save_json(existing_items, lvl_path)
                
                # è¿½åŠ ä¿å­˜é”™è¯¯ç»“æœ
                if error_to_save:
                    error_path = os.path.join(self._out_dir_for_save, f"error{file_ext}")
                    
                    if self._output_format == "jsonl":
                        # JSONL æ ¼å¼ï¼šé€è¡Œè¿½åŠ 
                        with open(error_path, "a", encoding="utf-8") as f:
                            for item in error_to_save:
                                item_id = str(item.get("id", ""))
                                if item_id and item_id not in self._saved_result_ids_for_save:
                                    f.write(json.dumps(item, ensure_ascii=False) + "\n")
                                    self._saved_result_ids_for_save.add(item_id)
                    else:
                        # JSON æ ¼å¼ï¼šè¯»å–ç°æœ‰æ•°æ®
                        existing_errors = []
                        if os.path.isfile(error_path):
                            try:
                                existing_data = load_json(error_path)
                                if isinstance(existing_data, list):
                                    existing_errors = existing_data
                            except Exception:
                                existing_errors = []
                        
                        # åˆå¹¶å¹¶å»é‡
                        existing_error_ids = {str(item.get("id", "")) for item in existing_errors}
                        for item in error_to_save:
                            item_id = str(item.get("id", ""))
                            if item_id not in existing_error_ids:
                                existing_errors.append(item)
                                existing_error_ids.add(item_id)
                        
                        save_json(existing_errors, error_path)
            
            saved_count = len(new_results_to_save)
            print(f"âœ… å·²ä¿å­˜ {saved_count} æ¡æœªä¿å­˜çš„ç»“æœåˆ° {self._out_dir_for_save}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æœªä¿å­˜ç»“æœå¤±è´¥: {e}")
            if self.debug_mode:
                import traceback
                traceback.print_exc()

    def _load_existing_results(self, output_dir: str) -> tuple:
        """
        ä»å·²æœ‰çš„ L1-L4.json/jsonl å’Œ error.json/jsonl ä¸­åŠ è½½å†å²ç»“æœï¼Œç”¨äºæ–­ç‚¹ç»­ä¼ /å¢é‡è¿½åŠ ã€‚
        
        Args:
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„
        
        Returns:
            (å†å²ç»“æœåˆ—è¡¨, é”™è¯¯ç»“æœåˆ—è¡¨) å…ƒç»„
        """
        if not os.path.isdir(output_dir):
            return [], []
        
        # ä½¿ç”¨å®ä¾‹çš„è¾“å‡ºæ ¼å¼
        is_jsonl = (self._output_format == "jsonl")
        
        # åŠ è½½æ­£å¸¸ç»“æœ
        existing_results: List[Dict] = []
        for lvl in DIFFICULTY_LEVELS:
            if is_jsonl:
                path = os.path.join(output_dir, f"{lvl}.jsonl")
            else:
                path = os.path.join(output_dir, f"{lvl}.json")
            
            if not os.path.isfile(path):
                continue
            try:
                if is_jsonl:
                    # JSONL æ ¼å¼ï¼šé€è¡Œè¯»å–
                    with open(path, "r", encoding="utf-8") as f:
                        for line in f:
                            line = line.strip()
                            if not line:
                                continue
                            try:
                                item = json.loads(line)
                                if isinstance(item, dict):
                                    existing_results.append(item)
                            except json.JSONDecodeError:
                                continue
                else:
                    # JSON æ ¼å¼ï¼šæ ‡å‡†è¯»å–
                    data = load_json(path)
                    if isinstance(data, list):
                        existing_results.extend(data)
            except Exception as e:
                print(f"âš ï¸ è¯»å–å†å²ç»“æœæ–‡ä»¶å¤±è´¥ï¼ˆ{path}ï¼‰: {e}")
        
        # åŠ è½½é”™è¯¯ç»“æœ
        error_results: List[Dict] = []
        if is_jsonl:
            error_path = os.path.join(output_dir, "error.jsonl")
        else:
            error_path = os.path.join(output_dir, "error.json")
        
        if os.path.isfile(error_path):
            try:
                if is_jsonl:
                    # JSONL æ ¼å¼ï¼šé€è¡Œè¯»å–
                    with open(error_path, "r", encoding="utf-8") as f:
                        for line in f:
                            line = line.strip()
                            if not line:
                                continue
                            try:
                                item = json.loads(line)
                                if isinstance(item, dict):
                                    error_results.append(item)
                            except json.JSONDecodeError:
                                continue
                else:
                    # JSON æ ¼å¼ï¼šæ ‡å‡†è¯»å–
                    data = load_json(error_path)
                    if isinstance(data, list):
                        error_results = data
                if error_results:
                    print(f"ğŸ”„ æ£€æµ‹åˆ°é”™è¯¯æ–‡ä»¶ {error_path}ï¼Œé”™è¯¯æ ·æœ¬æ•°: {len(error_results)}")
            except Exception as e:
                print(f"âš ï¸ è¯»å–é”™è¯¯ç»“æœæ–‡ä»¶å¤±è´¥ï¼ˆ{error_path}ï¼‰: {e}")
        
        if existing_results:
            print(f"ğŸ” æ£€æµ‹åˆ°å·²æœ‰è¾“å‡ºç›®å½• {output_dir}ï¼Œå†å²æ ·æœ¬æ•°: {len(existing_results)}")
        
        return existing_results, error_results

    def batch_evaluate(self, input_file: Optional[str] = None, output_dir: Optional[str] = None, 
                       output_format: str = "json", re_evaluate: bool = False):
        """
        æ‰¹é‡è¯„ä¼°ä¸»å…¥å£
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒ .json å’Œ .jsonl æ ¼å¼ï¼‰
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆæ–‡ä»¶å¤¹è·¯å¾„ï¼Œä¸éœ€è¦æ–‡ä»¶åï¼‰
            output_format: è¾“å‡ºæ ¼å¼ï¼Œjson æˆ– jsonlï¼ˆé»˜è®¤ï¼šjsonï¼‰
            re_evaluate: æ˜¯å¦é‡æ–°è¯„ä¼°ï¼ˆè·³è¿‡æ–­ç‚¹ç»­ä¼ ï¼Œç”Ÿæˆæ–°ç‰ˆæœ¬æ–‡ä»¶ï¼‰
        """
        # 1. è·¯å¾„è§£æ
        if input_file is None:
            raise ValueError(
                "æœªæŒ‡å®šè¾“å…¥æ–‡ä»¶ã€‚è¯·é€šè¿‡å‘½ä»¤è¡Œå‚æ•° --input <file_path> æä¾› "
                "ï¼ˆæ”¯æŒ .json å’Œ .jsonl æ ¼å¼ï¼‰ã€‚"
            )
        
        # éªŒè¯è¾“å‡ºæ ¼å¼
        if output_format not in ["json", "jsonl"]:
            raise ValueError(f"è¾“å‡ºæ ¼å¼å¿…é¡»æ˜¯ 'json' æˆ– 'jsonl'ï¼Œå½“å‰ä¸º: {output_format}")
        
        # è®¾ç½®è¾“å‡ºæ ¼å¼
        self._output_format = output_format
        
        if output_dir is None:
            # é»˜è®¤è¾“å‡ºåˆ° <output_dir>/module2_result
            output_dir = os.path.join(self.output_dir, "module2_result")
        
        # ç¡®ä¿è¾“å‡ºè·¯å¾„æ˜¯ç»å¯¹è·¯å¾„
        if not os.path.isabs(output_dir):
            # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼ŒåŸºäºé¡¹ç›®æ ¹ç›®å½•
            project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            output_dir = os.path.join(project_root, output_dir.lstrip("./"))
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        ensure_dir(output_dir)
        
        # åˆå§‹åŒ–æ—¥å¿—æ–‡ä»¶
        project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        log_dir = os.path.join(project_root, "module2_logs")
        self.log_file_path = init_log_file(
            log_dir=log_dir,
            input_file=input_file,
            output_file=output_dir,  # ä½¿ç”¨ç›®å½•è·¯å¾„
            max_workers=self.max_workers,
            batch_size=self.batch_size,
            debug_mode=self.debug_mode
        )
        print(f"ğŸ“ [æ—¥å¿—] æ—¥å¿—æ–‡ä»¶: {self.log_file_path}")
        
        print("=" * 60)
        print(f"ğŸš€ æ¨¡å—2ï¼šæ¨¡å‹è¯„ä¼°å¯åŠ¨")
        print(f"ğŸ“‚ è¾“å…¥: {input_file}")
        print(f"ğŸ’¾ è¾“å‡ºç›®å½•: {output_dir}")
        print(f"ğŸ“ è¾“å‡ºæ ¼å¼: {output_format}")
        print(f"âš™ï¸  å¹¶å‘: {self.max_workers} | Batch: {self.batch_size}")
        print("=" * 60)

        # 2. åŠ è½½è¾“å…¥æ•°æ®
        try:
            all_items = self._load_data(input_file)
        except Exception as e:
            print(f"âŒ æ— æ³•åŠ è½½è¾“å…¥æ–‡ä»¶: {e}")
            return
        
        # 3. æ ¹æ®æ˜¯å¦ re_evaluate å†³å®šæ˜¯å¦å¢é‡å¤„ç†
        existing_results: List[Dict] = []
        error_results: List[Dict] = []
        processed_ids: Set[str] = set()

        if not re_evaluate:
            # éé‡æ–°è¯„ä¼°æ¨¡å¼ï¼šå¦‚æœå·²æœ‰è¾“å‡ºç›®å½•ï¼Œåˆ™æŒ‰ id è·³è¿‡å·²å¤„ç†æ ·æœ¬ï¼Œå¹¶åŠ è½½é”™è¯¯ç»“æœ
            existing_results, error_results = self._load_existing_results(output_dir)
            for r in existing_results:
                rid = r.get("id")
                if rid is not None:
                    processed_ids.add(str(rid))
            if processed_ids:
                print(f"ğŸ” å·²å¤„ç†æ ·æœ¬æ•°ï¼ˆæ ¹æ® id å»é‡ï¼‰: {len(processed_ids)}")

        # å¤„ç†å¾…å¤„ç†çš„æ–°æ ·æœ¬
        if processed_ids:
            pending_items = [item for item in all_items if str(item.get("id")) not in processed_ids]
        else:
            pending_items = all_items

        print(f"ğŸ“Š æ€»æ•°: {len(all_items)} | å·²å¤„ç†: {len(processed_ids)} | æ–°å¢å¾…å¤„ç†: {len(pending_items)} | é”™è¯¯é‡è¯•: {len(error_results)}")
        
        # 4. å¹¶å‘æ‰§è¡Œæ–°æ ·æœ¬
        final_results: List[Dict] = []
        max_workers = self.max_workers
        
        # ä½¿ç”¨è¾“å‡ºç›®å½•ï¼ˆç›´æ¥ä½¿ç”¨ï¼Œä¸éœ€è¦æ¨å¯¼ï¼‰
        out_dir = output_dir
        ensure_dir(out_dir)
        
        # è¾“å‡ºæ ¼å¼æç¤º
        if self._output_format == "jsonl":
            print(f"ğŸ“ [è¾“å‡ºæ ¼å¼] ä½¿ç”¨ JSONL æ ¼å¼ï¼ˆå®æ—¶é€è¡Œè¿½åŠ å†™å…¥ï¼‰")
            print(f"   ğŸ’¡ JSONL æ ¼å¼ä¼˜åŠ¿ï¼šæ¯æ¡ç»“æœå®æ—¶å†™å…¥ï¼Œæ— éœ€bufferï¼Œbatchå‚æ•°ä¸ç”Ÿæ•ˆ")
        else:
            print(f"ğŸ“ [è¾“å‡ºæ ¼å¼] ä½¿ç”¨ JSON æ ¼å¼ï¼ˆæ‰¹é‡ä¿å­˜ï¼Œbatch={self.batch_size}ï¼‰")
            print(f"   ğŸ’¡ æç¤ºï¼šå¦‚éœ€å¤„ç†å¤§é‡æ•°æ®ï¼Œå»ºè®®ä½¿ç”¨ .jsonl æ ¼å¼ï¼ˆé€è¡Œè¿½åŠ ï¼Œæ€§èƒ½æ›´å¥½ï¼‰")
        
        # åˆå§‹åŒ–ä¸­æ–­ä¿å­˜ç›¸å…³å˜é‡
        self._final_results_for_save = final_results
        self._retry_results_for_save = []
        self._output_file_for_save = None  # ä¸å†ä½¿ç”¨æ–‡ä»¶è·¯å¾„
        self._out_dir_for_save = out_dir
        self._saved_result_ids_for_save = set()
        self._shutdown_requested = False
        self._result_buffer = []  # é‡ç½®ç¼“å†²åŒº
        
        # è®¾ç½®ä¿¡å·å¤„ç†å™¨ï¼ˆç”¨äºæ•è· Ctrl+C ç­‰ä¸­æ–­ä¿¡å·ï¼‰
        def signal_handler(signum, frame):
            """å¤„ç†ä¸­æ–­ä¿¡å·"""
            if self._shutdown_requested:
                # å¦‚æœå·²ç»è¯·æ±‚è¿‡å…³é—­ï¼Œå¼ºåˆ¶é€€å‡º
                print("\n\nâš ï¸  å¼ºåˆ¶é€€å‡º...")
                sys.exit(1)
            
            self._shutdown_requested = True
            print("\n\nâš ï¸  æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·ï¼ˆCtrl+Cï¼‰ï¼Œæ­£åœ¨ä¿å­˜å·²å¤„ç†çš„æ•°æ®...")
            self._save_unsaved_results()
            print("âœ… æ•°æ®å·²ä¿å­˜ï¼Œæ­£åœ¨é€€å‡º...")
            sys.exit(0)
        
        # æ³¨å†Œä¿¡å·å¤„ç†å™¨ï¼ˆSIGINT: Ctrl+C, SIGTERM: ç»ˆæ­¢ä¿¡å·ï¼‰
        original_sigint = signal.signal(signal.SIGINT, signal_handler)
        original_sigterm = signal.signal(signal.SIGTERM, signal_handler)
        
        # æ³¨å†Œé€€å‡ºæ—¶çš„ä¿å­˜å‡½æ•°ï¼ˆä½œä¸ºé¢å¤–ä¿éšœï¼‰
        def exit_handler():
            """ç¨‹åºé€€å‡ºæ—¶çš„æ¸…ç†å‡½æ•°"""
            if not self._shutdown_requested:
                self._save_unsaved_results()
        
        atexit.register(exit_handler)
        
        # è·Ÿè¸ªå·²ä¿å­˜çš„ç»“æœIDï¼Œé¿å…é‡å¤ä¿å­˜
        saved_result_ids: Set[str] = set()
        
        def save_checkpoint():
            """
            æ‰¹é‡ä¿å­˜ä¸­é—´ç»“æœåˆ° L1-L4.json å’Œ error.jsonï¼Œå®ç°çœŸæ­£çš„æ–­ç‚¹ç»­ä¼ ã€‚
            åªä¿å­˜æœ¬æ¬¡æ‰¹é‡å¤„ç†ä¸­æ–°å¢çš„ç»“æœï¼Œé¿å…é‡å¤ä¿å­˜ã€‚
            """
            # åŒæ­¥æ›´æ–°å®ä¾‹å˜é‡ï¼Œä»¥ä¾¿ä¿¡å·å¤„ç†å™¨å¯ä»¥è®¿é—®
            self._final_results_for_save = final_results
            self._saved_result_ids_for_save = saved_result_ids
            
            if not final_results:
                return
            
            # æ‰¾å‡ºæœ¬æ¬¡æ‰¹é‡ä¸­å°šæœªä¿å­˜çš„ç»“æœ
            new_results_to_save = []
            for res in final_results:
                res_id = str(res.get("id", ""))
                if res_id and res_id not in saved_result_ids:
                    new_results_to_save.append(res)
                    saved_result_ids.add(res_id)
            
            if not new_results_to_save:
                return
            
            # åŒæ­¥æ›´æ–°å·²ä¿å­˜çš„ID
            self._saved_result_ids_for_save = saved_result_ids
            
            try:
                # åˆ†ç¦»æ­£å¸¸ç»“æœå’Œé”™è¯¯ç»“æœ
                normal_to_save = []
                error_to_save = []
                for item in new_results_to_save:
                    if "model_error" in item or "error" in item:
                        error_to_save.append(item)
                    else:
                        normal_to_save.append(item)
                
                # æŒ‰éš¾åº¦çº§åˆ«åˆ†ç±»æ­£å¸¸ç»“æœ
                from collections import defaultdict
                level_buckets: Dict[str, List[Dict]] = defaultdict(list)
                for item in normal_to_save:
                    level = item.get("classification", {}).get("level", "Unknown")
                    if level not in DIFFICULTY_LEVELS:
                        level = "L4"
                    level_buckets[level].append(item)
                
                # ä½¿ç”¨çº¿ç¨‹é”ä¿è¯çº¿ç¨‹å®‰å…¨åœ°è¿½åŠ ä¿å­˜
                with file_lock:
                    file_ext = ".jsonl" if self._output_format == "jsonl" else ".json"
                    
                    # è¿½åŠ ä¿å­˜åˆ°å„éš¾åº¦çº§åˆ«æ–‡ä»¶
                    for lvl in DIFFICULTY_LEVELS:
                        new_items = level_buckets.get(lvl, [])
                        if not new_items:
                            continue
                        
                        lvl_path = os.path.join(out_dir, f"{lvl}{file_ext}")
                        
                        if self._output_format == "jsonl":
                            # JSONL æ ¼å¼ï¼šé€è¡Œè¿½åŠ 
                            with open(lvl_path, "a", encoding="utf-8") as f:
                                for item in new_items:
                                    item_id = str(item.get("id", ""))
                                    if item_id and item_id not in saved_result_ids:
                                        f.write(json.dumps(item, ensure_ascii=False) + "\n")
                                        saved_result_ids.add(item_id)
                        else:
                            # JSON æ ¼å¼ï¼šè¯»å–ç°æœ‰æ•°æ®
                            existing_items = []
                            if os.path.isfile(lvl_path):
                                try:
                                    existing_data = load_json(lvl_path)
                                    if isinstance(existing_data, list):
                                        existing_items = existing_data
                                except Exception:
                                    existing_items = []
                            
                            # åˆå¹¶å¹¶å»é‡ï¼ˆåŸºäºidï¼‰
                            existing_ids = {str(item.get("id", "")) for item in existing_items}
                            for item in new_items:
                                item_id = str(item.get("id", ""))
                                if item_id not in existing_ids:
                                    existing_items.append(item)
                                    existing_ids.add(item_id)
                            
                            # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
                            save_json(existing_items, lvl_path)
                    
                    # è¿½åŠ ä¿å­˜é”™è¯¯ç»“æœ
                    if error_to_save:
                        error_path = os.path.join(out_dir, f"error{file_ext}")
                        
                        if self._output_format == "jsonl":
                            # JSONL æ ¼å¼ï¼šé€è¡Œè¿½åŠ 
                            with open(error_path, "a", encoding="utf-8") as f:
                                for item in error_to_save:
                                    item_id = str(item.get("id", ""))
                                    if item_id and item_id not in saved_result_ids:
                                        f.write(json.dumps(item, ensure_ascii=False) + "\n")
                                        saved_result_ids.add(item_id)
                        else:
                            # JSON æ ¼å¼ï¼šè¯»å–ç°æœ‰æ•°æ®
                            existing_errors = []
                            if os.path.isfile(error_path):
                                try:
                                    existing_data = load_json(error_path)
                                    if isinstance(existing_data, list):
                                        existing_errors = existing_data
                                except Exception:
                                    existing_errors = []
                            
                            # åˆå¹¶å¹¶å»é‡
                            existing_error_ids = {str(item.get("id", "")) for item in existing_errors}
                            for item in error_to_save:
                                item_id = str(item.get("id", ""))
                                if item_id not in existing_error_ids:
                                    existing_errors.append(item)
                                    existing_error_ids.add(item_id)
                            
                            save_json(existing_errors, error_path)
                
                saved_count = len(new_results_to_save)
                print(f"ğŸ’¾ æ‰¹é‡ä¿å­˜æ£€æŸ¥ç‚¹: {saved_count} æ¡ç»“æœå·²ä¿å­˜åˆ° {out_dir}")
                
            except Exception as e:
                print(f"âš ï¸ æ‰¹é‡ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥: {e}")

        try:
            if pending_items:
                print("\nğŸ”„ å¤„ç†æ–°æ ·æœ¬...")
                with ThreadPoolExecutor(max_workers=max_workers) as executor:
                    future_to_item = {executor.submit(self.evaluate_item, item, False): item for item in pending_items}
                    
                    pbar = tqdm(total=len(pending_items), desc="Processing New", unit="q") if tqdm else None
                    
                    completed_in_session = 0
                    for future in as_completed(future_to_item):
                        # æ£€æŸ¥æ˜¯å¦è¯·æ±‚å…³é—­
                        if self._shutdown_requested:
                            print("\nâš ï¸  æ£€æµ‹åˆ°å…³é—­è¯·æ±‚ï¼Œæ­£åœ¨åœæ­¢å¤„ç†æ–°ä»»åŠ¡...")
                            # å–æ¶ˆæœªå®Œæˆçš„ä»»åŠ¡
                            for f in future_to_item:
                                f.cancel()
                            break
                        
                        res = future.result()
                        final_results.append(res)
                        # åŒæ­¥æ›´æ–°å®ä¾‹å˜é‡
                        self._final_results_for_save = final_results
                        
                        completed_in_session += 1
                        
                        # æ ¹æ®è¾“å‡ºæ ¼å¼é€‰æ‹©ä¿å­˜æ–¹å¼
                        if self._output_format == "jsonl":
                            # JSONL æ ¼å¼ï¼šå®æ—¶å†™å…¥
                            self._write_jsonl_item(res)
                            res_id = str(res.get("id", ""))
                            if res_id:
                                saved_result_ids.add(res_id)
                        else:
                            # JSON æ ¼å¼ï¼šåŠ å…¥ buffer
                            with self._buffer_lock:
                                self._result_buffer.append(res)
                                # å½“ buffer è¾¾åˆ° batch_size æ—¶ï¼Œæ‰¹é‡å†™å…¥
                                if len(self._result_buffer) >= self.batch_size:
                                    self._flush_buffer()
                        
                        # JSON æ ¼å¼çš„æ‰¹é‡ä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆç”¨äºç»Ÿè®¡å’Œæœ€ç»ˆä¿å­˜ï¼‰
                        if self._output_format == "json" and completed_in_session % self.batch_size == 0:
                            save_checkpoint()
                        
                        if pbar: pbar.update(1)
                    
                    # å¤„ç†å®Œæˆåï¼Œä¿å­˜å‰©ä½™çš„ç»“æœ
                    if self._output_format == "json":
                        # JSON æ ¼å¼ï¼šåˆ·æ–° buffer å’Œä¿å­˜æ£€æŸ¥ç‚¹
                        self._flush_buffer()
                        if final_results:
                            save_checkpoint()
                    # JSONL æ ¼å¼ï¼šå·²ç»å®æ—¶å†™å…¥ï¼Œæ— éœ€é¢å¤–ä¿å­˜
                    
                    if pbar: pbar.close()
        except KeyboardInterrupt:
            # æ•è·é”®ç›˜ä¸­æ–­ï¼ˆè™½ç„¶ä¿¡å·å¤„ç†å™¨åº”è¯¥å·²ç»å¤„ç†äº†ï¼Œä½†ä½œä¸ºé¢å¤–ä¿éšœï¼‰
            if not self._shutdown_requested:
                print("\nâš ï¸  æ£€æµ‹åˆ°é”®ç›˜ä¸­æ–­ï¼Œæ­£åœ¨ä¿å­˜æ•°æ®...")
                self._save_unsaved_results()
            raise
        except Exception as e:
            # æ•è·å…¶ä»–å¼‚å¸¸ï¼Œå°è¯•ä¿å­˜æ•°æ®
            print(f"\nâŒ å‘ç”Ÿå¼‚å¸¸: {e}")
            print("æ­£åœ¨å°è¯•ä¿å­˜å·²å¤„ç†çš„æ•°æ®...")
            self._save_unsaved_results()
            raise
        
        # 5. é‡è¯•é”™è¯¯æ ·æœ¬ï¼ˆåªè°ƒç”¨ä¹‹å‰å‡ºé”™çš„æ¨¡å‹ï¼‰
        retry_results: List[Dict] = []
        try:
            if error_results and not self._shutdown_requested:
                print("\nğŸ”„ é‡è¯•é”™è¯¯æ ·æœ¬...")
                with ThreadPoolExecutor(max_workers=max_workers) as executor:
                    future_to_item = {executor.submit(self.evaluate_item, item, True): item for item in error_results}
                    
                    pbar = tqdm(total=len(error_results), desc="Retry Errors", unit="q") if tqdm else None
                    
                    retry_completed = 0
                    for future in as_completed(future_to_item):
                        # æ£€æŸ¥æ˜¯å¦è¯·æ±‚å…³é—­
                        if self._shutdown_requested:
                            print("\nâš ï¸  æ£€æµ‹åˆ°å…³é—­è¯·æ±‚ï¼Œæ­£åœ¨åœæ­¢é‡è¯•ä»»åŠ¡...")
                            for f in future_to_item:
                                f.cancel()
                            break
                        
                        res = future.result()
                        retry_results.append(res)
                        # åŒæ­¥æ›´æ–°å®ä¾‹å˜é‡
                        self._retry_results_for_save = retry_results
                        
                        retry_completed += 1
                        
                        # æ ¹æ®è¾“å‡ºæ ¼å¼é€‰æ‹©ä¿å­˜æ–¹å¼
                        if self._output_format == "jsonl":
                            # JSONL æ ¼å¼ï¼šå®æ—¶å†™å…¥
                            self._write_jsonl_item(res)
                            res_id = str(res.get("id", ""))
                            if res_id:
                                saved_result_ids.add(res_id)
                        else:
                            # JSON æ ¼å¼ï¼šåŠ å…¥ buffer
                            with self._buffer_lock:
                                self._result_buffer.append(res)
                                # å½“ buffer è¾¾åˆ° batch_size æ—¶ï¼Œæ‰¹é‡å†™å…¥
                                if len(self._result_buffer) >= self.batch_size:
                                    self._flush_buffer()
                        
                        # JSON æ ¼å¼çš„æ‰¹é‡ä¿å­˜æ£€æŸ¥ç‚¹
                        if self._output_format == "json" and retry_completed % self.batch_size == 0:
                            final_results.extend(retry_results)
                            save_checkpoint()
                            # æ¸…ç©ºå·²ä¿å­˜çš„é‡è¯•ç»“æœï¼Œé¿å…é‡å¤
                            retry_results = []
                            self._retry_results_for_save = []
                        
                        if pbar: pbar.update(1)
                    
                    # é‡è¯•å®Œæˆåï¼Œä¿å­˜å‰©ä½™çš„é‡è¯•ç»“æœ
                    if self._output_format == "json":
                        # JSON æ ¼å¼ï¼šåˆ·æ–° buffer å’Œä¿å­˜æ£€æŸ¥ç‚¹
                        self._flush_buffer()
                        if retry_results:
                            final_results.extend(retry_results)
                            save_checkpoint()
                            retry_results = []
                            self._retry_results_for_save = []
                    # JSONL æ ¼å¼ï¼šå·²ç»å®æ—¶å†™å…¥ï¼Œæ— éœ€é¢å¤–ä¿å­˜
                    
                    if pbar: pbar.close()
        except KeyboardInterrupt:
            if not self._shutdown_requested:
                print("\nâš ï¸  æ£€æµ‹åˆ°é”®ç›˜ä¸­æ–­ï¼Œæ­£åœ¨ä¿å­˜æ•°æ®...")
                self._save_unsaved_results()
            raise
        except Exception as e:
            print(f"\nâŒ é‡è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
            print("æ­£åœ¨å°è¯•ä¿å­˜å·²å¤„ç†çš„æ•°æ®...")
            self._save_unsaved_results()
            raise
        finally:
            # æ¢å¤åŸå§‹ä¿¡å·å¤„ç†å™¨
            signal.signal(signal.SIGINT, original_sigint)
            signal.signal(signal.SIGTERM, original_sigterm)
        
        # å¦‚æœè¢«ä¸­æ–­ï¼Œç›´æ¥è¿”å›ï¼ˆæ•°æ®å·²åœ¨ä¿¡å·å¤„ç†å™¨ä¸­ä¿å­˜ï¼‰
        if self._shutdown_requested:
            return
        
        # 6. æ¸…ç†erroræ–‡ä»¶ä¸­å·²æˆåŠŸé‡è¯•çš„è®°å½•
        if retry_results:
            self._cleanup_successful_retries_from_error_file(out_dir, retry_results)
        
        # åˆå¹¶æ‰€æœ‰ç»“æœï¼šå†å²æ­£å¸¸ç»“æœ + æ–°å¤„ç†ç»“æœ + é‡è¯•ç»“æœ
        all_results = existing_results + final_results + retry_results

        # ä¸å†è¾“å‡ºä¸»ç»“æœ JSONï¼Œä»…è¾“å‡ºæŒ‰ç­‰çº§åˆ’åˆ†çš„æ–‡ä»¶å¤¹
        print(f"\nâœ… å¤„ç†å®Œæˆï¼ç»“æœå·²è¾“å‡ºåˆ°æ–‡ä»¶å¤¹: {os.path.abspath(out_dir)}")
        
        # æ‰“å°å¹¶è®°å½•ç»Ÿè®¡ä¿¡æ¯
        stats_text = self._print_stats(all_results, return_text=True)
        from module2.logger import log_stats
        log_stats(stats_text)
        
        # åœ¨å•ç‹¬çš„æ–‡ä»¶å¤¹ä¸­è¾“å‡º L1-L4 & æ±‡æ€»æ–‡ä»¶ï¼ˆå…¨é‡ï¼šå†å² + æ–°å¢ï¼‰
        self._save_by_level_and_summary(all_results, out_dir)
        
        # è®°å½•è¾“å‡ºæ–‡ä»¶ä¿¡æ¯åˆ°æ—¥å¿—
        from module2.logger import log_output_info
        log_output_info(out_dir)
        
        # å…³é—­æ—¥å¿—æ–‡ä»¶
        close_log_file()

    def _print_stats(self, results: List[Dict], return_text: bool = False):
        """
        æ‰“å°ç»Ÿè®¡æ‘˜è¦
        
        Args:
            results: ç»“æœåˆ—è¡¨
            return_text: æ˜¯å¦è¿”å›æ–‡æœ¬ï¼ˆç”¨äºå†™å…¥æ—¥å¿—ï¼‰
        
        Returns:
            å¦‚æœ return_text=Trueï¼Œè¿”å›ç»Ÿè®¡æ–‡æœ¬ï¼›å¦åˆ™è¿”å› None
        """
        # åˆ†ç¦»æ­£å¸¸ç»“æœå’Œé”™è¯¯ç»“æœ
        normal_results = [r for r in results if "model_error" not in r and "error" not in r]
        error_results = [r for r in results if "model_error" in r or "error" in r]
        
        # æ‰“å°åˆ†éš”çº¿ï¼ˆæ§åˆ¶å°è¾“å‡ºï¼‰
        if not return_text:
            print("\n" + "=" * 30 + " è¯„ä¼°ç»Ÿè®¡ " + "=" * 30)
        
        # æ„å»ºç»Ÿè®¡æ–‡æœ¬
        stats_lines = []
        stats_lines.append(f"æ€»æ ·æœ¬æ•°: {len(results)}")
        stats_lines.append(f"  - æ­£å¸¸å¤„ç†: {len(normal_results)} ({len(normal_results)/len(results)*100:.1f}%)")
        if error_results:
            stats_lines.append(f"  - æ¨¡å‹é”™è¯¯: {len(error_results)} ({len(error_results)/len(results)*100:.1f}%)")
        stats_lines.append("")
        
        # ä½¿ç”¨æ­£å¸¸ç»“æœè¿›è¡Œåç»­ç»Ÿè®¡
        valid = normal_results

        # ---------------- å…¨å±€åŒ¹é…ç‡ï¼ˆæŒ‰æ¨¡å‹ï¼‰ ----------------
        for m in MODEL_KEYS:
            enabled_count = sum(1 for r in valid if r.get(m, {}).get("enabled"))
            match_count = sum(1 for r in valid if r.get(m, {}).get("enabled") and r.get(m, {}).get("match_gt"))
            if enabled_count > 0:
                line = f"[{m}] å‡†ç¡®ç‡: {match_count}/{enabled_count} ({match_count/enabled_count*100:.1f}%)"
                stats_lines.append(line)
                print(line)

        # ---------------- æŒ‰é¢˜å‹ç»Ÿè®¡æ­£ç¡®ç‡ ----------------
        stats_lines.append("")
        stats_lines.append("æŒ‰ question_type ç»Ÿè®¡æ­£ç¡®ç‡ï¼ˆåŸºäºè£åˆ¤ç»“æœ match_gtï¼‰:")
        print("\næŒ‰ question_type ç»Ÿè®¡æ­£ç¡®ç‡ï¼ˆåŸºäºè£åˆ¤ç»“æœ match_gtï¼‰:")
        qt_stats = self._calculate_stats_by_field(valid, "question_type")
        for qtype, models in qt_stats.items():
            stats_lines.append(f"  é¢˜å‹ {qtype}:")
            print(f"  é¢˜å‹ {qtype}:")
            for m, (enabled_cnt, match_cnt) in models.items():
                acc = match_cnt / enabled_cnt * 100 if enabled_cnt > 0 else 0.0
                line = f"    - {m}: {match_cnt}/{enabled_cnt} ({acc:.1f}%)"
                stats_lines.append(line)
                print(line)

        # ---------------- æŒ‰å›¾ç‰‡ç±»å‹ç»Ÿè®¡æ­£ç¡®ç‡ ----------------
        stats_lines.append("")
        stats_lines.append("æŒ‰ image_type ç»Ÿè®¡æ­£ç¡®ç‡:")
        print("\næŒ‰ image_type ç»Ÿè®¡æ­£ç¡®ç‡:")
        img_stats = self._calculate_stats_by_field(valid, "image_type")
        for itype, models in img_stats.items():
            stats_lines.append(f"  å›¾ç‰‡ç±»å‹ {itype}:")
            print(f"  å›¾ç‰‡ç±»å‹ {itype}:")
            for m, (enabled_cnt, match_cnt) in models.items():
                acc = match_cnt / enabled_cnt * 100 if enabled_cnt > 0 else 0.0
                line = f"    - {m}: {match_cnt}/{enabled_cnt} ({acc:.1f}%)"
                stats_lines.append(line)
                print(line)
        
        # ---------------- éš¾åº¦åˆ†å¸ƒ ----------------
        levels = {}
        for r in valid:
            lvl = r.get("classification", {}).get("level", "Unknown")
            levels[lvl] = levels.get(lvl, 0) + 1
        
        stats_lines.append("")
        stats_lines.append("éš¾åº¦åˆ†å¸ƒï¼ˆL1-L4ï¼‰:")
        print("\néš¾åº¦åˆ†å¸ƒï¼ˆL1-L4ï¼‰:")
        for l in DIFFICULTY_LEVELS:
            count = levels.get(l, 0)
            if count > 0:
                line = f"  {l}: {count} ({count/len(valid)*100:.1f}%)"
                stats_lines.append(line)
                print(line)
        
        # æ‰“å°ç»“æŸåˆ†éš”çº¿ï¼ˆæ§åˆ¶å°è¾“å‡ºï¼‰
        if not return_text:
            print("=" * 70)
        
        if return_text:
            return "\n".join(stats_lines)
    
    def _calculate_stats_by_field(self, valid_results: List[Dict], field_name: str) -> Dict:
        """
        æŒ‰æŒ‡å®šå­—æ®µç»Ÿè®¡æ¨¡å‹æ­£ç¡®ç‡ï¼ˆé€šç”¨æ–¹æ³•ï¼Œç”¨äºæŒ‰é¢˜å‹ã€å›¾ç‰‡ç±»å‹ç­‰ç»Ÿè®¡ï¼‰
        
        Args:
            valid_results: æœ‰æ•ˆç»“æœåˆ—è¡¨
            field_name: å­—æ®µåï¼ˆå¦‚ "question_type", "image_type"ï¼‰
        
        Returns:
            {å­—æ®µå€¼: {æ¨¡å‹é”®: [enabled_count, match_count]}}
        """
        stats = {}
        for r in valid_results:
            field_value = r.get(field_name, "Unknown")
            bucket = stats.setdefault(field_value, {})
            for m in MODEL_KEYS:
                mdata = r.get(m, {})
                if not mdata.get("enabled"):
                    continue
                model_bucket = bucket.setdefault(m, [0, 0])
                model_bucket[0] += 1
                if mdata.get("match_gt"):
                    model_bucket[1] += 1
        return stats

    def _cleanup_successful_retries_from_error_file(self, output_dir: str, retry_results: List[Dict]):
        """
        æ¸…ç†erroræ–‡ä»¶ä¸­å·²æˆåŠŸé‡è¯•çš„è®°å½•
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
            retry_results: é‡è¯•ç»“æœåˆ—è¡¨
        """
        # æ‰¾å‡ºæˆåŠŸå¤„ç†çš„é‡è¯•ç»“æœï¼ˆä¸å†æœ‰model_erroræˆ–erroræ ‡è®°ï¼‰
        successful_retry_ids = set()
        for res in retry_results:
            res_id = str(res.get("id", ""))
            if res_id and "model_error" not in res and "error" not in res:
                successful_retry_ids.add(res_id)
        
        if not successful_retry_ids:
            return
        
        # ç¡®å®šerroræ–‡ä»¶è·¯å¾„
        file_ext = ".jsonl" if self._output_format == "jsonl" else ".json"
        error_path = os.path.join(output_dir, f"error{file_ext}")
        
        if not os.path.isfile(error_path):
            return
        
        try:
            if self._output_format == "jsonl":
                # JSONL æ ¼å¼ï¼šé€è¡Œè¯»å–ï¼Œè¿‡æ»¤æ‰å·²æˆåŠŸå¤„ç†çš„è®°å½•
                remaining_errors = []
                with open(error_path, "r", encoding="utf-8") as f:
                    for line in f:
                        line = line.strip()
                        if not line:
                            continue
                        try:
                            item = json.loads(line)
                            item_id = str(item.get("id", ""))
                            # å¦‚æœè¿™ä¸ªIDä¸åœ¨æˆåŠŸé‡è¯•åˆ—è¡¨ä¸­ï¼Œä¿ç•™å®ƒ
                            if item_id not in successful_retry_ids:
                                remaining_errors.append(line)
                        except json.JSONDecodeError:
                            # å¦‚æœè§£æå¤±è´¥ï¼Œä¿ç•™åŸè¡Œï¼ˆå¯èƒ½æ˜¯æ ¼å¼é—®é¢˜ï¼Œä½†ä¿ç•™æ›´å®‰å…¨ï¼‰
                            remaining_errors.append(line)
                
                # é‡æ–°å†™å…¥erroræ–‡ä»¶
                with open(error_path, "w", encoding="utf-8") as f:
                    for line in remaining_errors:
                        f.write(line + "\n")
                
                removed_count = len(successful_retry_ids)
                remaining_count = len(remaining_errors)
                if removed_count > 0:
                    print(f"ğŸ§¹ å·²ä»erroræ–‡ä»¶ä¸­åˆ é™¤ {removed_count} æ¡æˆåŠŸé‡è¯•çš„è®°å½•ï¼Œå‰©ä½™ {remaining_count} æ¡é”™è¯¯è®°å½•")
            else:
                # JSON æ ¼å¼ï¼šè¯»å–ã€è¿‡æ»¤ã€ä¿å­˜
                existing_errors = []
                try:
                    data = load_json(error_path)
                    if isinstance(data, list):
                        existing_errors = data
                except Exception:
                    existing_errors = []
                
                # è¿‡æ»¤æ‰å·²æˆåŠŸå¤„ç†çš„è®°å½•
                remaining_errors = []
                for item in existing_errors:
                    item_id = str(item.get("id", ""))
                    if item_id not in successful_retry_ids:
                        remaining_errors.append(item)
                
                # ä¿å­˜æ›´æ–°åçš„erroræ–‡ä»¶
                save_json(remaining_errors, error_path)
                
                removed_count = len(successful_retry_ids)
                remaining_count = len(remaining_errors)
                if removed_count > 0:
                    print(f"ğŸ§¹ å·²ä»erroræ–‡ä»¶ä¸­åˆ é™¤ {removed_count} æ¡æˆåŠŸé‡è¯•çš„è®°å½•ï¼Œå‰©ä½™ {remaining_count} æ¡é”™è¯¯è®°å½•")
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†erroræ–‡ä»¶å¤±è´¥: {e}")
            if self.debug_mode:
                import traceback
                traceback.print_exc()

    def _save_by_level_and_summary(self, results: List[Dict], output_dir: str):
        """
        è¾“å‡ºç»“æ„ï¼š
        - ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼ŒåŒ…å«ï¼š
          - L1.json/jsonl ~ L4.json/jsonlï¼šä¸åŒéš¾åº¦çº§åˆ«çš„é—®é¢˜ç»“æœï¼ˆå®Œæ•´ item åˆ—è¡¨ï¼‰
          - error.json/jsonlï¼šæ¨¡å‹ç”Ÿæˆå‡ºé”™çš„é¢˜ç›®ï¼ˆä¸åŒ…å«åœ¨ L1-L4 ä¸­ï¼‰
          - summary.jsonï¼šç»Ÿè®¡å½“å‰ï¼ˆä»¥åŠå†å²è¿½åŠ ï¼‰åˆ†ç±»æƒ…å†µ
        """
        from collections import defaultdict

        # 1ï¼‰å‡†å¤‡ç›®å½•
        ensure_dir(output_dir)

        # 2ï¼‰åˆ†ç¦»æ­£å¸¸ç»“æœå’Œé”™è¯¯ç»“æœ
        normal_results: List[Dict] = []
        error_results: List[Dict] = []
        
        for item in results:
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¨¡å‹é”™è¯¯æˆ–å…¶ä»–é”™è¯¯
            if "model_error" in item or "error" in item:
                error_results.append(item)
            else:
                normal_results.append(item)
        
        # 3ï¼‰ä¿å­˜é”™è¯¯ç»“æœåˆ° error.json/jsonl
        if error_results:
            file_ext = ".jsonl" if self._output_format == "jsonl" else ".json"
            error_path = os.path.join(output_dir, f"error{file_ext}")
            try:
                if self._output_format == "jsonl":
                    # JSONL æ ¼å¼ï¼šé€è¡Œå†™å…¥
                    with open(error_path, "w", encoding="utf-8") as f:
                        for item in error_results:
                            f.write(json.dumps(item, ensure_ascii=False) + "\n")
                else:
                    # JSON æ ¼å¼ï¼šæ ‡å‡†ä¿å­˜
                    save_json(error_results, error_path)
                print(f"âš ï¸  å·²è¾“å‡ºé”™è¯¯æ ·æœ¬ {len(error_results)} æ¡ -> {error_path}")
            except Exception as e:
                print(f"âŒ ä¿å­˜ error{file_ext} å¤±è´¥: {e}")

        # 4ï¼‰æŒ‰ level æ‹†åˆ†æ­£å¸¸ç»“æœåˆ° L1-L4ï¼ˆä¸å†æœ‰ L0ï¼‰
        level_buckets: Dict[str, List[Dict]] = defaultdict(list)
        for item in normal_results:
            level = item.get("classification", {}).get("level", "Unknown")
            # å¦‚æœé‡åˆ° L0 æˆ– Unknownï¼Œç»Ÿä¸€å½’ç±»åˆ° L4
            if level not in DIFFICULTY_LEVELS:
                level = "L4"
            level_buckets[level].append(item)

        # æ ¹æ®è¾“å‡ºæ ¼å¼é€‰æ‹©æ–‡ä»¶æ‰©å±•å
        file_ext = ".jsonl" if self._output_format == "jsonl" else ".json"
        
        for lvl in DIFFICULTY_LEVELS:
            items = level_buckets.get(lvl, [])
            out_path = os.path.join(output_dir, f"{lvl}{file_ext}")
            try:
                if self._output_format == "jsonl":
                    # JSONL æ ¼å¼ï¼šé€è¡Œå†™å…¥
                    with open(out_path, "w", encoding="utf-8") as f:
                        for item in items:
                            f.write(json.dumps(item, ensure_ascii=False) + "\n")
                else:
                    # JSON æ ¼å¼ï¼šæ ‡å‡†ä¿å­˜
                    save_json(items, out_path)
                print(f"ğŸ’¾ å·²è¾“å‡º {lvl} çº§æ ·æœ¬ {len(items)} æ¡ -> {out_path}")
            except Exception as e:
                print(f"âŒ ä¿å­˜ {lvl} æ–‡ä»¶å¤±è´¥: {e}")

        # 5ï¼‰ç”Ÿæˆ/æ›´æ–° summary.jsonï¼ˆä»…ç»Ÿè®¡æ­£å¸¸ç»“æœï¼‰
        #    - å¯¹äºæ–­ç‚¹ç»­ä¼ ï¼šnormal_results å·²ç»åŒ…å«å†å² + æ–°å¢æ•°æ®ï¼Œè¿™é‡Œç›´æ¥"å…¨é‡é‡ç®—"ä¸€æ¬¡ç»Ÿè®¡å³å¯
        #    - å¯¹äºé‡æ–°è¯„ä¼°ï¼ˆre_evaluateï¼‰ï¼šç”±å¤–å±‚æŒ‡å®šå…¨æ–°çš„è¾“å‡ºç›®å½•ï¼Œè¿™é‡Œå§‹ç»ˆåŸºäºå½“å‰ normal_results å…¨é‡é‡ç®—
        summary_path = os.path.join(output_dir, "summary.json")

        # å½“å‰è¿™ä¸€æ¬¡è¿è¡Œçš„ç»Ÿè®¡
        current_summary = {
            "total_items": len(normal_results),
            "error_items": len(error_results),
            "levels": {},
            "by_question_type": {},
            "by_image_type": {},
            "models": {key: {"enabled": 0, "correct": 0} for key in MODEL_KEYS},
            # è¿™é‡Œçš„ runs ä»£è¡¨"åŸºäºå½“å‰ results å…¨é‡é‡ç®—çš„ç‰ˆæœ¬å·"ï¼Œ
            # ç›®å‰ç®€å•å¤„ç†ä¸ºï¼šå¦‚æœå­˜åœ¨æ—§ summaryï¼Œåˆ™åœ¨å…¶åŸºç¡€ä¸Š +1ï¼Œå¦åˆ™ä¸º 1
            "runs": 1
        }

        # çº§åˆ«ç»Ÿè®¡ï¼ˆä¸å†æœ‰ L0ï¼‰
        for lvl in DIFFICULTY_LEVELS:
            current_summary["levels"][lvl] = len(level_buckets.get(lvl, []))

        # æŒ‰é¢˜å‹ & éš¾åº¦ç»Ÿè®¡
        for item in normal_results:
            qtype = item.get("question_type", "Unknown")
            lvl = item.get("classification", {}).get("level", "Unknown")
            qt_bucket = current_summary["by_question_type"].setdefault(qtype, {})
            qt_bucket[lvl] = qt_bucket.get(lvl, 0) + 1

            itype = item.get("image_type", "Unknown")
            it_bucket = current_summary["by_image_type"].setdefault(itype, {})
            it_bucket[lvl] = it_bucket.get(lvl, 0) + 1

            for m in MODEL_KEYS:
                mdata = item.get(m, {})
                if not mdata.get("enabled"):
                    continue
                current_summary["models"][m]["enabled"] += 1
                if mdata.get("match_gt"):
                    current_summary["models"][m]["correct"] += 1

        # å¦‚æœå·²æœ‰ summary.jsonï¼Œåˆ™ä»…æ›´æ–° runsï¼ˆè¡¨ç¤ºé‡æ–°è®¡ç®—è¿‡å¤šå°‘æ¬¡ï¼‰ï¼Œ
        # å…¶å®ƒç»Ÿè®¡å…¨éƒ¨ä»¥ current_summary ä¸ºå‡†ï¼ˆé¿å…æ–­ç‚¹ç»­ä¼ æ—¶é‡å¤ç´¯åŠ ï¼‰
        if os.path.exists(summary_path):
            try:
                old = load_json(summary_path)
                if isinstance(old, dict):
                    current_summary["runs"] = old.get("runs", 0) + 1
            except Exception as e:
                print(f"âš ï¸ è¯»å–æ—§çš„ summary.json å¤±è´¥ï¼Œå°†ä»…ä¿å­˜æœ¬æ¬¡ç»Ÿè®¡: {e}")

        try:
            save_json(current_summary, summary_path)
            print(f"ğŸ“Š å·²æ›´æ–°æ±‡æ€»ç»Ÿè®¡ -> {summary_path}")
        except Exception as e:
            print(f"âŒ ä¿å­˜ summary.json å¤±è´¥: {e}")


    def _get_versioned_output_file(self, base_output_file: str) -> str:
        """
        ç”Ÿæˆå¸¦ç‰ˆæœ¬å·çš„è¾“å‡ºæ–‡ä»¶å
        
        æ³¨æ„ï¼šæ­¤æ–¹æ³•ç›®å‰ä¸å†ä½¿ç”¨ï¼Œç‰ˆæœ¬å·ç®¡ç†å·²ç§»è‡³ shell è„šæœ¬ï¼ˆmain.shï¼‰ã€‚
        ä¿ç•™æ­¤æ–¹æ³•ä»¥é˜²å°†æ¥éœ€è¦ã€‚
        
        ä¾‹å¦‚ï¼š
        - module2_result.json -> module2_result_v2.json
        - module2_result_v2.json -> module2_result_v3.json
        
        Args:
            base_output_file: åŸºç¡€è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            å¸¦ç‰ˆæœ¬å·çš„æ–‡ä»¶è·¯å¾„
        """
        # åˆ†ç¦»ç›®å½•ã€æ–‡ä»¶åå’Œæ‰©å±•å
        output_dir = os.path.dirname(base_output_file)
        base_name = os.path.basename(base_output_file)
        
        # åˆ†ç¦»æ–‡ä»¶åå’Œæ‰©å±•å
        if '.' in base_name:
            name_part, ext = os.path.splitext(base_name)
        else:
            name_part = base_name
            ext = ""
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç‰ˆæœ¬å·ï¼ˆæ ¼å¼ï¼šname_v2.extï¼‰
        version_pattern = r'_v(\d+)$'
        match = re.search(version_pattern, name_part)
        
        if match:
            # å·²æœ‰ç‰ˆæœ¬å·ï¼Œæå–å¹¶åŠ 1
            current_version = int(match.group(1))
            base_name_part = name_part[:match.start()]
            next_version = current_version + 1
        else:
            # æ²¡æœ‰ç‰ˆæœ¬å·ï¼ŒæŸ¥æ‰¾ç›®å½•ä¸­æ˜¯å¦æœ‰åŒåæ–‡ä»¶çš„ä¸åŒç‰ˆæœ¬
            base_name_part = name_part
            current_version = 0
            
            # æŸ¥æ‰¾ç›®å½•ä¸­æ‰€æœ‰åŒåæ–‡ä»¶çš„ä¸åŒç‰ˆæœ¬
            if output_dir and os.path.exists(output_dir):
                pattern = re.compile(rf'^{re.escape(name_part)}_v(\d+){re.escape(ext)}$')
                for filename in os.listdir(output_dir):
                    match = pattern.match(filename)
                    if match:
                        version = int(match.group(1))
                        if version > current_version:
                            current_version = version
            
            next_version = current_version + 1
        
        # ç”Ÿæˆæ–°ç‰ˆæœ¬æ–‡ä»¶å
        new_name = f"{base_name_part}_v{next_version}{ext}"
        return os.path.join(output_dir, new_name) if output_dir else new_name

def main():
    parser = argparse.ArgumentParser(description="æ¨¡å—2ï¼šæ¨¡å‹è¯„ä¼°")
    parser.add_argument("--input", type=str, help="è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒ .json å’Œ .jsonl æ ¼å¼ï¼‰")
    parser.add_argument("--output", type=str, help="è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆæ–‡ä»¶å¤¹è·¯å¾„ï¼Œä¸éœ€è¦æ–‡ä»¶åï¼‰")
    parser.add_argument("--output-format", type=str, default="json", choices=["json", "jsonl"],
                       help="è¾“å‡ºæ ¼å¼ï¼šjson æˆ– jsonlï¼ˆé»˜è®¤ï¼šjsonï¼‰")
    parser.add_argument("-re", "--re", action="store_true", 
                       help="é‡æ–°è¯„ä¼°æ¨¡å¼ï¼šè·³è¿‡æ–­ç‚¹ç»­ä¼ ï¼Œå§‹ç»ˆå¯¹è¾“å…¥æ–‡ä»¶ä¸­çš„æ‰€æœ‰æ ·æœ¬é‡æ–°è¯„ä¼°ï¼ˆä¸å¤ç”¨å·²æœ‰ç»“æœï¼‰")
    parser.add_argument("--workers", type=int, default=None,
                       help="å¹¶å‘çº¿ç¨‹æ•°ï¼ˆè¦†ç›–é»˜è®¤å€¼ï¼‰")
    parser.add_argument("--batch", type=int, default=None,
                       help="æ‰¹é‡ä¿å­˜å¤§å°ï¼ˆè¦†ç›–é»˜è®¤å€¼ï¼‰")
    parser.add_argument("--debug", action="store_true",
                       help="å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼ˆæ‰“å° tracebackã€judge_reasoning ç­‰ï¼‰")
    
    args = parser.parse_args()
    
    evaluator = Module2ModelEvaluation(
        max_workers=args.workers,
        batch_size=args.batch,
        debug_mode=args.debug,
    )
    evaluator.batch_evaluate(
        input_file=args.input, 
        output_dir=args.output, 
        output_format=args.output_format,
        re_evaluate=args.re
    )

if __name__ == "__main__":
    main()